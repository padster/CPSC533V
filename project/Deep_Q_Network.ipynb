{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q Network\n",
    "\n",
    "Train a Q(s, a) function, using trajectories of (s, a, r, s', a', r', s'', ...) from matches.\n",
    "\n",
    "Using a memory of previous (s, a, r, s'), and double Q networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "EXPERT_PLAYER_IDX = 0\n",
    "USE_GPU = False\n",
    "\n",
    "GAMES = [{\"id\": gameID} for gameID in [\"noBoost1v1_1\", \"noBoost1v1_2\", \"noBoost1v1_3\"]]\n",
    "\n",
    "# NOTE: can't use __file__ in jupyter notebook unfortunately, so hard-code it insteadL\n",
    "ROOT_PROJECT_PATH = 'C:/Users/User/code/CPSC533V/project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "DEVICE = torch.device(\"cuda\" if USE_GPU else \"cpu\")\n",
    "\n",
    "# Load local reusable code within 'lib/'\n",
    "sys.path.append(ROOT_PROJECT_PATH)\n",
    "import lib.files as libFiles\n",
    "import lib.preprocess as libPreprocess\n",
    "from lib.SAtoVModel import SAtoV_Model\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess all replays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n",
      "\treplays\\noBoost1v1_1.replay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find field_of_view in camera settings for Sundown\n",
      "Could not find height in camera settings for Sundown\n",
      "Could not find pitch in camera settings for Sundown\n",
      "Could not find distance in camera settings for Sundown\n",
      "Could not find stiffness in camera settings for Sundown\n",
      "Could not find swivel_speed in camera settings for Sundown\n",
      "Could not find transition_speed in camera settings for Sundown\n",
      "D:/projects/carball\\carball\\controls\\rotations.py:87: RuntimeWarning: invalid value encountered in sign\n",
      "  rhs[1] / (T_p + np.sign(rhs[1]) * omega[1] * D_p),\n",
      "D:/projects/carball\\carball\\controls\\rotations.py:88: RuntimeWarning: invalid value encountered in sign\n",
      "  rhs[2] / (T_y - np.sign(rhs[2]) * omega[2] * D_y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 players loaded!\n",
      "\n",
      "Orange team:\n",
      "\tbot\n",
      "\n",
      "Blue team:\n",
      "\texpert\n",
      "\n",
      "12921 data points acquired\n",
      "====\n",
      "\n",
      "\n",
      "Game data from 'noBoost1v1_1' preprocessed.\n",
      "    ... clean data available at 'playerStates', 'playerActions' and 'ballStates' keys\n",
      "\n",
      "State and action maps for player expert\n",
      "(12921, 29) float64\n",
      "(12921, 3) object\n",
      "=======\n",
      "\n",
      "\n",
      "Loading...\n",
      "\treplays\\noBoost1v1_2.replay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find field_of_view in camera settings for Beast\n",
      "Could not find height in camera settings for Beast\n",
      "Could not find pitch in camera settings for Beast\n",
      "Could not find distance in camera settings for Beast\n",
      "Could not find stiffness in camera settings for Beast\n",
      "Could not find swivel_speed in camera settings for Beast\n",
      "Could not find transition_speed in camera settings for Beast\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 players loaded!\n",
      "\n",
      "Orange team:\n",
      "\tbot\n",
      "\n",
      "Blue team:\n",
      "\texpert\n",
      "\n",
      "12016 data points acquired\n",
      "====\n",
      "\n",
      "\n",
      "Game data from 'noBoost1v1_2' preprocessed.\n",
      "    ... clean data available at 'playerStates', 'playerActions' and 'ballStates' keys\n",
      "\n",
      "State and action maps for player expert\n",
      "(12016, 29) float64\n",
      "(12016, 3) object\n",
      "=======\n",
      "\n",
      "\n",
      "Loading...\n",
      "\treplays\\noBoost1v1_3.replay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find field_of_view in camera settings for Middy\n",
      "Could not find height in camera settings for Middy\n",
      "Could not find pitch in camera settings for Middy\n",
      "Could not find distance in camera settings for Middy\n",
      "Could not find stiffness in camera settings for Middy\n",
      "Could not find swivel_speed in camera settings for Middy\n",
      "Could not find transition_speed in camera settings for Middy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 players loaded!\n",
      "\n",
      "Orange team:\n",
      "\tbot\n",
      "\n",
      "Blue team:\n",
      "\texpert\n",
      "\n",
      "12682 data points acquired\n",
      "====\n",
      "\n",
      "\n",
      "Game data from 'noBoost1v1_3' preprocessed.\n",
      "    ... clean data available at 'playerStates', 'playerActions' and 'ballStates' keys\n",
      "\n",
      "State and action maps for player expert\n",
      "(12682, 29) float64\n",
      "(12682, 3) object\n",
      "=======\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for game in GAMES:\n",
    "    game['data'] = libFiles.parseReplayToGameData(game['id'])\n",
    "    libFiles.cleanAndDisplayGameData(game['data'])\n",
    "    \n",
    "    game['playerStates'], game['playerActions'] = [], []\n",
    "    for p in game['data'].players:\n",
    "        game['playerStates' ].append(libPreprocess.cleanPlayerStates( p.data    ))\n",
    "        game['playerActions'].append(libPreprocess.cleanPlayerActions(p.controls))\n",
    "    game['ballStates'] = libPreprocess.cleanBallStates(game['data'].ball)\n",
    "    print (\"Game data from '%s' preprocessed.\" % game['id'])\n",
    "    print (\"    ... clean data available at 'playerStates', 'playerActions' and 'ballStates' keys\\n\")\n",
    "    \n",
    "    game['expertStates'], game['expertActions'] = libPreprocess.stateAndActionsForPlayer(game, EXPERT_PLAYER_IDX)\n",
    "    print (\"State and action maps for player %s\" % game['data'].players[EXPERT_PLAYER_IDX].name)\n",
    "    print (game['expertStates'].values.shape, game['expertStates'].values.dtype)\n",
    "    print (game['expertActions'].values.shape, game['expertActions'].values.dtype)\n",
    "    print (\"=======\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_EPOCHS = 500\n",
    "BATCH_SZ = 100\n",
    "#PRINT_INTERVAL = 1000\n",
    "LOG_INTERVAL = 1000\n",
    "LEARNING_RATE = 0.0001\n",
    "REGULARIZER_WEIGHT = 3e-4\n",
    "GAMMA = 0.7\n",
    "Q_SWAP_EPOCHS = 20\n",
    "\n",
    "W_ALOSS = 100\n",
    "W_DLOSS = 50\n",
    "\n",
    "writer = SummaryWriter(filename_suffix=\"dqn\")\n",
    "\n",
    "\"\"\"\n",
    "# Continuous 3D action space, so we can't find the maximum easily.\n",
    "# Instead, sample over a small subset of actions\n",
    "#  * Throttle takes values [100% back, nothing, 100% forwards]\n",
    "#  * Steer takes values [100% left, nothing, 100% right]\n",
    "def maxQ(state, qModel, nT=3, nS=3):\n",
    "    batchMax = None\n",
    "    for tValue in range(nT):\n",
    "        throttle = 2 * tValue / (nT - 1) - 1 # [-1, 1]\n",
    "        for sValue in range(nS):\n",
    "            steer = 2 * sValue / (nS - 1) - 1 # [-1, 1]\n",
    "            for boost in [0.0, 1.0]:\n",
    "                aArray = np.repeat(np.array([[tValue, sValue, boost]]), state.shape[0], axis=0)\n",
    "                sa = torch.cat((state, torch.from_numpy(aArray).float()), dim=1)\n",
    "                q = qModel(sa).detach().numpy() # Detach, we don't need gradients through here\n",
    "                if batchMax is None:\n",
    "                    batchMax = q\n",
    "                else:\n",
    "                    batchMax = np.maximum(batchMax, q)\n",
    "    return batchMax\n",
    "\"\"\"\n",
    "\n",
    "def train_behavioral_cloning(dataBatches, thisQ, nextQ):   \n",
    "    # Adam optimizer usually a good default.\n",
    "    optimizer = torch.optim.Adam(thisQ.parameters(), lr=LEARNING_RATE, weight_decay=REGULARIZER_WEIGHT)\n",
    "    \n",
    "    # MSE loss\n",
    "    loss_function = torch.nn.MSELoss().to(DEVICE)\n",
    "\n",
    "    gradient_steps = 0\n",
    "\n",
    "    for epoch in range(1, TOTAL_EPOCHS + 1):\n",
    "        batchShuffled = random.sample(dataBatches, len(dataBatches))\n",
    "        lastLoss, lastAverageR, lastAverageQ = -1, -1, -1\n",
    "        for iteration, data in enumerate(batchShuffled):\n",
    "            data = {k: v.to(DEVICE) for k, v in data.items()}\n",
    "            saCombined = torch.cat((data['s'], data['a']), dim=1)\n",
    "            \n",
    "            maxQCalc = libRewards.bestQ(nextQ, data['sPrime'], returnAction=False)\n",
    "            y_j_torch = data['r'] + GAMMA * maxQCalc\n",
    "            y_pred = thisQ(saCombined)\n",
    "    \n",
    "            # Gradient descent on MSE loss between predicted and calculated Q\n",
    "            loss = loss_function(y_j_torch, y_pred)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if gradient_steps % LOG_INTERVAL == 0:\n",
    "                writer.add_scalar('loss', loss.item(), gradient_steps)\n",
    "            \n",
    "            gradient_steps += 1\n",
    "            \n",
    "            if iteration == len(batchShuffled) - 1:\n",
    "                lastLoss = loss.item()\n",
    "                lastAverageR = np.mean(data['r'].detach().numpy())\n",
    "                lastAverageQ = np.mean(maxQCalc)\n",
    "            \n",
    "        print ('[epoch {:4d}/{}] [iter {:7d}] [loss {:.5f}] [av. R {:.5f}] [av. Q {:.5f}]'.format(\n",
    "           epoch, TOTAL_EPOCHS, gradient_steps, lastLoss, lastAverageR, lastAverageQ)\n",
    "        )\n",
    "        \n",
    "        if (epoch + 1) % Q_SWAP_EPOCHS == 0:\n",
    "            nextQ.load_state_dict(thisQ.state_dict())\n",
    "            nextQ.eval()\n",
    "            print (\"Copying Q weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class QModel(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(QModel, self).__init__()\n",
    "        \n",
    "        self.dimIn          = state_size + action_size # (s, a)\n",
    "        self.dimH1          = 32 # hidden layer 1 has 32 dimensions\n",
    "        self.dimH2          = 8  # hidden layer 2 has 32 dimensions\n",
    "        self.dimOut         = 1 # scalar value, Q(s, a)\n",
    "     \n",
    "        self.model = torch.nn.Sequential(\n",
    "            nn.Linear(self.dimIn, self.dimH1),\n",
    "            nn.BatchNorm1d(self.dimH1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.dimH1, self.dimH2),\n",
    "            nn.BatchNorm1d(self.dimH2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.dimH2, self.dimOut),\n",
    "        )\n",
    "        self.model.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input data type needs to be converted to float\n",
    "        return self.model(x.float())\n",
    "        \n",
    "    def save(self, modelID):\n",
    "        path = os.path.join(\"models\", \"%s.pt\" % modelID)\n",
    "        torch.save(self.state_dict(), path)\n",
    "        print('Saved model!\\n\\t%s' % path)\n",
    "        \n",
    "    def load(self, modelID):\n",
    "        path = os.path.join(\"models\", \"%s.pt\" % modelID)\n",
    "        self.load_state_dict(torch.load(path))\n",
    "        print('Loaded model!\\n\\t%s' % path)\n",
    "\"\"\";    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "random.seed(1234)\n",
    "\n",
    "# Return list of batches, each a list of (s, a, r, s') tuples\n",
    "def dataToBatches(states, actions, batchSz):\n",
    "    nRows = states.shape[0]\n",
    "    stateSz = states.shape[1]\n",
    "    actionSz = actions.shape[1]\n",
    "    print (\"%d rows, %d state dim, %d action dim, into %d batches of size %d\" % (\n",
    "        nRows, stateSz, actionSz, (nRows + batchSz - 1) // batchSz, batchSz\n",
    "    ))\n",
    "\n",
    "    tOrder = list(range(0, nRows - 1))\n",
    "    random.shuffle(tOrder)\n",
    "    \n",
    "    dataBatches = []\n",
    "    for i in range(0, len(tOrder), batchSz):\n",
    "        nInBatch = min(batchSz, len(tOrder) - i)\n",
    "        \n",
    "        s = np.zeros((nInBatch, stateSz))\n",
    "        a = np.zeros((nInBatch, actionSz))\n",
    "        r = np.zeros((nInBatch))\n",
    "        sPrime = np.zeros((nInBatch, stateSz))\n",
    "        \n",
    "        for j in range(nInBatch):\n",
    "            t = tOrder[i + j]\n",
    "            s[j, :] = states.iloc[t, :].values\n",
    "            a[j, :] = actions.iloc[t, :].values\n",
    "            sPrime[j, :] = states.iloc[t+1, :].values\n",
    "            r[j] = artificialReward(states.iloc[t+1, :], a[j, :]) # reward based off goodness of next state\n",
    "            \n",
    "        dataBatches.append({\n",
    "            's': torch.from_numpy(s).float(),\n",
    "            'a': torch.from_numpy(a).float(),\n",
    "            'r': torch.from_numpy(r).float(),\n",
    "            'sPrime': torch.from_numpy(sPrime).float()\n",
    "        })\n",
    "            \n",
    "    return dataBatches, stateSz, actionSz\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37619 rows, 29 state dim, 3 action dim, into 377 batches of size 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\rlstats\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([100, 1])) that is different to the input size (torch.Size([100, 100])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\rlstats\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([18, 1])) that is different to the input size (torch.Size([18, 18])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch    1/500] [iter     377] [loss 1.48407] [av. R 0.88126] [av. Q -0.21951]\n",
      "[epoch    2/500] [iter     754] [loss 1.02454] [av. R 0.86937] [av. Q -0.22306]\n",
      "[epoch    3/500] [iter    1131] [loss 0.66379] [av. R 0.84855] [av. Q -0.21891]\n",
      "[epoch    4/500] [iter    1508] [loss 0.44188] [av. R 0.87522] [av. Q -0.22152]\n",
      "[epoch    5/500] [iter    1885] [loss 0.25523] [av. R 0.87161] [av. Q -0.22144]\n",
      "[epoch    6/500] [iter    2262] [loss 0.16910] [av. R 0.88283] [av. Q -0.22291]\n",
      "[epoch    7/500] [iter    2639] [loss 0.10631] [av. R 0.86441] [av. Q -0.22334]\n",
      "[epoch    8/500] [iter    3016] [loss 0.07023] [av. R 0.86441] [av. Q -0.22334]\n",
      "[epoch    9/500] [iter    3393] [loss 0.04131] [av. R 0.84238] [av. Q -0.21940]\n",
      "[epoch   10/500] [iter    3770] [loss 0.04668] [av. R 0.87938] [av. Q -0.22160]\n",
      "[epoch   11/500] [iter    4147] [loss 0.03632] [av. R 0.87036] [av. Q -0.22144]\n",
      "[epoch   12/500] [iter    4524] [loss 0.02602] [av. R 0.85567] [av. Q -0.21858]\n",
      "[epoch   13/500] [iter    4901] [loss 0.04041] [av. R 0.84662] [av. Q -0.22561]\n",
      "[epoch   14/500] [iter    5278] [loss 0.03755] [av. R 0.84335] [av. Q -0.22183]\n",
      "[epoch   15/500] [iter    5655] [loss 0.02831] [av. R 0.85727] [av. Q -0.22119]\n",
      "[epoch   16/500] [iter    6032] [loss 0.02775] [av. R 0.84296] [av. Q -0.22057]\n",
      "[epoch   17/500] [iter    6409] [loss 0.02835] [av. R 0.89534] [av. Q -0.22329]\n",
      "[epoch   18/500] [iter    6786] [loss 0.02706] [av. R 0.86349] [av. Q -0.21934]\n",
      "[epoch   19/500] [iter    7163] [loss 0.02899] [av. R 0.85878] [av. Q -0.22134]\n",
      "Copying Q weights\n",
      "[epoch   20/500] [iter    7540] [loss 0.07923] [av. R 0.87030] [av. Q 0.75323]\n",
      "[epoch   21/500] [iter    7917] [loss 0.04877] [av. R 0.88675] [av. Q 0.75566]\n",
      "[epoch   22/500] [iter    8294] [loss 0.04379] [av. R 0.89531] [av. Q 0.75110]\n",
      "[epoch   23/500] [iter    8671] [loss 0.03564] [av. R 0.88527] [av. Q 0.75690]\n",
      "[epoch   24/500] [iter    9048] [loss 0.03646] [av. R 0.83486] [av. Q 0.75575]\n",
      "[epoch   25/500] [iter    9425] [loss 0.02532] [av. R 0.90008] [av. Q 0.75527]\n",
      "[epoch   26/500] [iter    9802] [loss 0.03049] [av. R 0.87673] [av. Q 0.75775]\n",
      "[epoch   27/500] [iter   10179] [loss 0.03017] [av. R 0.85499] [av. Q 0.75757]\n",
      "[epoch   28/500] [iter   10556] [loss 0.03718] [av. R 0.85373] [av. Q 0.76144]\n",
      "[epoch   29/500] [iter   10933] [loss 0.03518] [av. R 0.86182] [av. Q 0.75333]\n",
      "[epoch   30/500] [iter   11310] [loss 0.03622] [av. R 0.89953] [av. Q 0.75477]\n",
      "[epoch   31/500] [iter   11687] [loss 0.03143] [av. R 0.85544] [av. Q 0.75875]\n",
      "[epoch   32/500] [iter   12064] [loss 0.03209] [av. R 0.89167] [av. Q 0.75770]\n",
      "[epoch   33/500] [iter   12441] [loss 0.03372] [av. R 0.87293] [av. Q 0.75078]\n",
      "[epoch   34/500] [iter   12818] [loss 0.03010] [av. R 0.87998] [av. Q 0.75939]\n",
      "[epoch   35/500] [iter   13195] [loss 0.03024] [av. R 0.87953] [av. Q 0.75785]\n",
      "[epoch   36/500] [iter   13572] [loss 0.03221] [av. R 0.87443] [av. Q 0.75952]\n",
      "[epoch   37/500] [iter   13949] [loss 0.02630] [av. R 0.85019] [av. Q 0.75508]\n",
      "[epoch   38/500] [iter   14326] [loss 0.02808] [av. R 0.88038] [av. Q 0.76381]\n",
      "[epoch   39/500] [iter   14703] [loss 0.03431] [av. R 0.85291] [av. Q 0.76080]\n",
      "Copying Q weights\n",
      "[epoch   40/500] [iter   15080] [loss 0.02666] [av. R 0.86546] [av. Q 1.42643]\n",
      "[epoch   41/500] [iter   15457] [loss 0.03466] [av. R 0.88349] [av. Q 1.43447]\n",
      "[epoch   42/500] [iter   15834] [loss 0.03424] [av. R 0.83582] [av. Q 1.43496]\n",
      "[epoch   43/500] [iter   16211] [loss 0.02248] [av. R 0.87696] [av. Q 1.43131]\n",
      "[epoch   44/500] [iter   16588] [loss 0.02923] [av. R 0.86420] [av. Q 1.42256]\n",
      "[epoch   45/500] [iter   16965] [loss 0.02729] [av. R 0.86588] [av. Q 1.42062]\n",
      "[epoch   46/500] [iter   17342] [loss 0.03250] [av. R 0.89210] [av. Q 1.42469]\n",
      "[epoch   47/500] [iter   17719] [loss 0.02485] [av. R 0.88003] [av. Q 1.43162]\n",
      "[epoch   48/500] [iter   18096] [loss 0.03703] [av. R 0.86210] [av. Q 1.42883]\n",
      "[epoch   49/500] [iter   18473] [loss 0.02875] [av. R 0.87768] [av. Q 1.43590]\n",
      "[epoch   50/500] [iter   18850] [loss 0.02626] [av. R 0.85978] [av. Q 1.43265]\n",
      "[epoch   51/500] [iter   19227] [loss 0.03511] [av. R 0.86852] [av. Q 1.43298]\n",
      "[epoch   52/500] [iter   19604] [loss 0.03054] [av. R 0.87998] [av. Q 1.42959]\n",
      "[epoch   53/500] [iter   19981] [loss 0.02506] [av. R 0.89529] [av. Q 1.42284]\n",
      "[epoch   54/500] [iter   20358] [loss 0.02757] [av. R 0.86040] [av. Q 1.42990]\n",
      "[epoch   55/500] [iter   20735] [loss 0.03540] [av. R 0.87297] [av. Q 1.42870]\n",
      "[epoch   56/500] [iter   21112] [loss 0.02845] [av. R 0.90268] [av. Q 1.43049]\n",
      "[epoch   57/500] [iter   21489] [loss 0.02738] [av. R 0.84020] [av. Q 1.42670]\n",
      "[epoch   58/500] [iter   21866] [loss 0.02943] [av. R 0.88906] [av. Q 1.45106]\n",
      "[epoch   59/500] [iter   22243] [loss 0.02700] [av. R 0.85019] [av. Q 1.42501]\n",
      "Copying Q weights\n",
      "[epoch   60/500] [iter   22620] [loss 0.02933] [av. R 0.87412] [av. Q 1.89403]\n",
      "[epoch   61/500] [iter   22997] [loss 0.02468] [av. R 0.91800] [av. Q 1.89378]\n",
      "[epoch   62/500] [iter   23374] [loss 0.03219] [av. R 0.86668] [av. Q 1.89068]\n",
      "[epoch   63/500] [iter   23751] [loss 0.03474] [av. R 0.85141] [av. Q 1.89035]\n",
      "[epoch   64/500] [iter   24128] [loss 0.02661] [av. R 0.87506] [av. Q 1.89750]\n",
      "[epoch   65/500] [iter   24505] [loss 0.03271] [av. R 0.85131] [av. Q 1.90048]\n",
      "[epoch   66/500] [iter   24882] [loss 0.02722] [av. R 0.89478] [av. Q 1.88842]\n",
      "[epoch   67/500] [iter   25259] [loss 0.02680] [av. R 0.88790] [av. Q 1.88959]\n",
      "[epoch   68/500] [iter   25636] [loss 0.03252] [av. R 0.85718] [av. Q 1.89435]\n",
      "[epoch   69/500] [iter   26013] [loss 0.02269] [av. R 0.88330] [av. Q 1.89533]\n",
      "[epoch   70/500] [iter   26390] [loss 0.02817] [av. R 0.87622] [av. Q 1.89414]\n",
      "[epoch   71/500] [iter   26767] [loss 0.03034] [av. R 0.87671] [av. Q 1.88843]\n",
      "[epoch   72/500] [iter   27144] [loss 0.02425] [av. R 0.87220] [av. Q 1.88367]\n",
      "[epoch   73/500] [iter   27521] [loss 0.03402] [av. R 0.86563] [av. Q 1.89180]\n",
      "[epoch   74/500] [iter   27898] [loss 0.03018] [av. R 0.88356] [av. Q 1.89211]\n",
      "[epoch   75/500] [iter   28275] [loss 0.02986] [av. R 0.86217] [av. Q 1.89194]\n",
      "[epoch   76/500] [iter   28652] [loss 0.02901] [av. R 0.87181] [av. Q 1.89282]\n",
      "[epoch   77/500] [iter   29029] [loss 0.03534] [av. R 0.87152] [av. Q 1.88565]\n",
      "[epoch   78/500] [iter   29406] [loss 0.03035] [av. R 0.85509] [av. Q 1.88849]\n",
      "[epoch   79/500] [iter   29783] [loss 0.02906] [av. R 0.85049] [av. Q 1.89448]\n",
      "Copying Q weights\n",
      "[epoch   80/500] [iter   30160] [loss 0.03072] [av. R 0.87173] [av. Q 2.20027]\n",
      "[epoch   81/500] [iter   30537] [loss 0.02539] [av. R 0.86765] [av. Q 2.20547]\n",
      "[epoch   82/500] [iter   30914] [loss 0.03205] [av. R 0.88349] [av. Q 2.20819]\n",
      "[epoch   83/500] [iter   31291] [loss 0.02163] [av. R 0.89355] [av. Q 2.20562]\n",
      "[epoch   84/500] [iter   31668] [loss 0.02077] [av. R 0.87877] [av. Q 2.20618]\n",
      "[epoch   85/500] [iter   32045] [loss 0.02558] [av. R 0.86623] [av. Q 2.20922]\n",
      "[epoch   86/500] [iter   32422] [loss 0.02590] [av. R 0.88110] [av. Q 2.20671]\n",
      "[epoch   87/500] [iter   32799] [loss 0.02664] [av. R 0.88692] [av. Q 2.19864]\n",
      "[epoch   88/500] [iter   33176] [loss 0.03005] [av. R 0.89210] [av. Q 2.20468]\n",
      "[epoch   89/500] [iter   33553] [loss 0.02836] [av. R 0.85899] [av. Q 2.20955]\n",
      "[epoch   90/500] [iter   33930] [loss 0.02884] [av. R 0.88309] [av. Q 2.20138]\n",
      "[epoch   91/500] [iter   34307] [loss 0.02974] [av. R 0.88498] [av. Q 2.20602]\n",
      "[epoch   92/500] [iter   34684] [loss 0.03536] [av. R 0.81679] [av. Q 2.20551]\n",
      "[epoch   93/500] [iter   35061] [loss 0.02440] [av. R 0.87908] [av. Q 2.20286]\n",
      "[epoch   94/500] [iter   35438] [loss 0.02616] [av. R 0.86925] [av. Q 2.20901]\n",
      "[epoch   95/500] [iter   35815] [loss 0.03250] [av. R 0.86668] [av. Q 2.20692]\n",
      "[epoch   96/500] [iter   36192] [loss 0.02487] [av. R 0.89057] [av. Q 2.20702]\n",
      "[epoch   97/500] [iter   36569] [loss 0.02657] [av. R 0.90166] [av. Q 2.21198]\n",
      "[epoch   98/500] [iter   36946] [loss 0.02867] [av. R 0.87235] [av. Q 2.20243]\n",
      "[epoch   99/500] [iter   37323] [loss 0.03411] [av. R 0.86420] [av. Q 2.21702]\n",
      "Copying Q weights\n",
      "[epoch  100/500] [iter   37700] [loss 0.02962] [av. R 0.87036] [av. Q 2.41082]\n",
      "[epoch  101/500] [iter   38077] [loss 0.02640] [av. R 0.85816] [av. Q 2.41635]\n",
      "[epoch  102/500] [iter   38454] [loss 0.03303] [av. R 0.88352] [av. Q 2.41397]\n",
      "[epoch  103/500] [iter   38831] [loss 0.03047] [av. R 0.84873] [av. Q 2.41748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch  104/500] [iter   39208] [loss 0.02550] [av. R 0.86274] [av. Q 2.42104]\n",
      "[epoch  105/500] [iter   39585] [loss 0.02642] [av. R 0.86349] [av. Q 2.42475]\n",
      "[epoch  106/500] [iter   39962] [loss 0.03234] [av. R 0.85513] [av. Q 2.41235]\n",
      "[epoch  107/500] [iter   40339] [loss 0.02906] [av. R 0.86346] [av. Q 2.41446]\n",
      "[epoch  108/500] [iter   40716] [loss 0.02771] [av. R 0.88066] [av. Q 2.40792]\n",
      "[epoch  109/500] [iter   41093] [loss 0.02097] [av. R 0.88399] [av. Q 2.41680]\n",
      "[epoch  110/500] [iter   41470] [loss 0.02778] [av. R 0.86666] [av. Q 2.41721]\n",
      "[epoch  111/500] [iter   41847] [loss 0.02346] [av. R 0.87109] [av. Q 2.41602]\n",
      "[epoch  112/500] [iter   42224] [loss 0.02483] [av. R 0.86323] [av. Q 2.41653]\n",
      "[epoch  113/500] [iter   42601] [loss 0.02949] [av. R 0.89210] [av. Q 2.41456]\n",
      "[epoch  114/500] [iter   42978] [loss 0.02921] [av. R 0.88156] [av. Q 2.41856]\n",
      "[epoch  115/500] [iter   43355] [loss 0.02349] [av. R 0.87109] [av. Q 2.41602]\n",
      "[epoch  116/500] [iter   43732] [loss 0.02448] [av. R 0.87239] [av. Q 2.41581]\n",
      "[epoch  117/500] [iter   44109] [loss 0.02517] [av. R 0.89577] [av. Q 2.41220]\n",
      "[epoch  118/500] [iter   44486] [loss 0.02596] [av. R 0.86888] [av. Q 2.41913]\n",
      "[epoch  119/500] [iter   44863] [loss 0.02686] [av. R 0.88038] [av. Q 2.41428]\n",
      "Copying Q weights\n",
      "[epoch  120/500] [iter   45240] [loss 0.01954] [av. R 0.88826] [av. Q 2.56704]\n",
      "[epoch  121/500] [iter   45617] [loss 0.02614] [av. R 0.86689] [av. Q 2.56750]\n",
      "[epoch  122/500] [iter   45994] [loss 0.03061] [av. R 0.87915] [av. Q 2.57091]\n",
      "[epoch  123/500] [iter   46371] [loss 0.02583] [av. R 0.84020] [av. Q 2.57453]\n",
      "[epoch  124/500] [iter   46748] [loss 0.02677] [av. R 0.86313] [av. Q 2.56359]\n",
      "[epoch  125/500] [iter   47125] [loss 0.02483] [av. R 0.87196] [av. Q 2.57626]\n",
      "[epoch  126/500] [iter   47502] [loss 0.02790] [av. R 0.89051] [av. Q 2.56473]\n",
      "[epoch  127/500] [iter   47879] [loss 0.02432] [av. R 0.85657] [av. Q 2.57164]\n",
      "[epoch  128/500] [iter   48256] [loss 0.02689] [av. R 0.87506] [av. Q 2.57097]\n",
      "[epoch  129/500] [iter   48633] [loss 0.03327] [av. R 0.87171] [av. Q 2.57229]\n",
      "[epoch  130/500] [iter   49010] [loss 0.02770] [av. R 0.85499] [av. Q 2.56793]\n",
      "[epoch  131/500] [iter   49387] [loss 0.03217] [av. R 0.85749] [av. Q 2.57004]\n",
      "[epoch  132/500] [iter   49764] [loss 0.01947] [av. R 0.90226] [av. Q 2.56971]\n",
      "[epoch  133/500] [iter   50141] [loss 0.02668] [av. R 0.84147] [av. Q 2.57017]\n",
      "[epoch  134/500] [iter   50518] [loss 0.03396] [av. R 0.85291] [av. Q 2.56962]\n",
      "[epoch  135/500] [iter   50895] [loss 0.02844] [av. R 0.86994] [av. Q 2.56527]\n",
      "[epoch  136/500] [iter   51272] [loss 0.02919] [av. R 0.86420] [av. Q 2.56756]\n",
      "[epoch  137/500] [iter   51649] [loss 0.02647] [av. R 0.86463] [av. Q 2.57298]\n",
      "[epoch  138/500] [iter   52026] [loss 0.02778] [av. R 0.86923] [av. Q 2.56604]\n",
      "[epoch  139/500] [iter   52403] [loss 0.03363] [av. R 0.87342] [av. Q 2.57421]\n",
      "Copying Q weights\n",
      "[epoch  140/500] [iter   52780] [loss 0.02736] [av. R 0.87953] [av. Q 2.66969]\n",
      "[epoch  141/500] [iter   53157] [loss 0.03242] [av. R 0.85564] [av. Q 2.66095]\n",
      "[epoch  142/500] [iter   53534] [loss 0.04114] [av. R 0.86262] [av. Q 2.66255]\n",
      "[epoch  143/500] [iter   53911] [loss 0.02847] [av. R 0.85099] [av. Q 2.66334]\n",
      "[epoch  144/500] [iter   54288] [loss 0.02321] [av. R 0.88122] [av. Q 2.66744]\n",
      "[epoch  145/500] [iter   54665] [loss 0.03392] [av. R 0.86420] [av. Q 2.67021]\n",
      "[epoch  146/500] [iter   55042] [loss 0.02573] [av. R 0.87622] [av. Q 2.66253]\n",
      "[epoch  147/500] [iter   55419] [loss 0.02617] [av. R 0.86313] [av. Q 2.65893]\n",
      "[epoch  148/500] [iter   55796] [loss 0.02831] [av. R 0.85902] [av. Q 2.66251]\n",
      "[epoch  149/500] [iter   56173] [loss 0.02777] [av. R 0.86309] [av. Q 2.66736]\n",
      "[epoch  150/500] [iter   56550] [loss 0.02115] [av. R 0.89875] [av. Q 2.66357]\n",
      "[epoch  151/500] [iter   56927] [loss 0.03219] [av. R 0.85131] [av. Q 2.67172]\n",
      "[epoch  152/500] [iter   57304] [loss 0.03092] [av. R 0.85921] [av. Q 2.66201]\n",
      "[epoch  153/500] [iter   57681] [loss 0.02557] [av. R 0.85816] [av. Q 2.66509]\n",
      "[epoch  154/500] [iter   58058] [loss 0.02295] [av. R 0.89353] [av. Q 2.66123]\n",
      "[epoch  155/500] [iter   58435] [loss 0.02484] [av. R 0.89126] [av. Q 2.66931]\n",
      "[epoch  156/500] [iter   58812] [loss 0.02913] [av. R 0.85332] [av. Q 2.66389]\n",
      "[epoch  157/500] [iter   59189] [loss 0.02246] [av. R 0.85567] [av. Q 2.66164]\n",
      "[epoch  158/500] [iter   59566] [loss 0.02823] [av. R 0.85679] [av. Q 2.66919]\n",
      "[epoch  159/500] [iter   59943] [loss 0.01965] [av. R 0.88826] [av. Q 2.66173]\n",
      "Copying Q weights\n",
      "[epoch  160/500] [iter   60320] [loss 0.03215] [av. R 0.85131] [av. Q 2.74171]\n",
      "[epoch  161/500] [iter   60697] [loss 0.03392] [av. R 0.83486] [av. Q 2.73333]\n",
      "[epoch  162/500] [iter   61074] [loss 0.02443] [av. R 0.87798] [av. Q 2.73554]\n",
      "[epoch  163/500] [iter   61451] [loss 0.03011] [av. R 0.85693] [av. Q 2.73692]\n",
      "[epoch  164/500] [iter   61828] [loss 0.02613] [av. R 0.83983] [av. Q 2.73234]\n",
      "[epoch  165/500] [iter   62205] [loss 0.02865] [av. R 0.90268] [av. Q 2.73877]\n",
      "[epoch  166/500] [iter   62582] [loss 0.03438] [av. R 0.84569] [av. Q 2.73657]\n",
      "[epoch  167/500] [iter   62959] [loss 0.02791] [av. R 0.88066] [av. Q 2.73065]\n",
      "[epoch  168/500] [iter   63336] [loss 0.02763] [av. R 0.87452] [av. Q 2.73481]\n",
      "[epoch  169/500] [iter   63713] [loss 0.03698] [av. R 0.88222] [av. Q 2.74121]\n",
      "[epoch  170/500] [iter   64090] [loss 0.01771] [av. R 0.89061] [av. Q 2.73514]\n",
      "[epoch  171/500] [iter   64467] [loss 0.02746] [av. R 0.85499] [av. Q 2.73556]\n",
      "[epoch  172/500] [iter   64844] [loss 0.03349] [av. R 0.87342] [av. Q 2.73766]\n",
      "[epoch  173/500] [iter   65221] [loss 0.02357] [av. R 0.91800] [av. Q 2.73117]\n",
      "[epoch  174/500] [iter   65598] [loss 0.03319] [av. R 0.83486] [av. Q 2.73333]\n",
      "[epoch  175/500] [iter   65975] [loss 0.02824] [av. R 0.86182] [av. Q 2.73625]\n",
      "[epoch  176/500] [iter   66352] [loss 0.02376] [av. R 0.87811] [av. Q 2.73406]\n",
      "[epoch  177/500] [iter   66729] [loss 0.02186] [av. R 0.87037] [av. Q 2.73377]\n",
      "[epoch  178/500] [iter   67106] [loss 0.02887] [av. R 0.88309] [av. Q 2.73436]\n",
      "[epoch  179/500] [iter   67483] [loss 0.02435] [av. R 0.85019] [av. Q 2.73755]\n",
      "Copying Q weights\n",
      "[epoch  180/500] [iter   67860] [loss 0.02794] [av. R 0.84838] [av. Q 2.78511]\n",
      "[epoch  181/500] [iter   68237] [loss 0.03484] [av. R 0.81679] [av. Q 2.78485]\n",
      "[epoch  182/500] [iter   68614] [loss 0.02614] [av. R 0.86588] [av. Q 2.78343]\n",
      "[epoch  183/500] [iter   68991] [loss 0.02486] [av. R 0.89618] [av. Q 2.78278]\n",
      "[epoch  184/500] [iter   69368] [loss 0.02593] [av. R 0.86645] [av. Q 2.79228]\n",
      "[epoch  185/500] [iter   69745] [loss 0.03235] [av. R 0.87283] [av. Q 2.78383]\n",
      "[epoch  186/500] [iter   70122] [loss 0.03276] [av. R 0.86937] [av. Q 2.78307]\n",
      "[epoch  187/500] [iter   70499] [loss 0.03420] [av. R 0.86563] [av. Q 2.78328]\n",
      "[epoch  188/500] [iter   70876] [loss 0.02142] [av. R 0.86756] [av. Q 2.79220]\n",
      "[epoch  189/500] [iter   71253] [loss 0.03007] [av. R 0.88164] [av. Q 2.78898]\n",
      "[epoch  190/500] [iter   71630] [loss 0.03148] [av. R 0.87369] [av. Q 2.78311]\n",
      "[epoch  191/500] [iter   72007] [loss 0.02550] [av. R 0.86765] [av. Q 2.78501]\n",
      "[epoch  192/500] [iter   72384] [loss 0.03216] [av. R 0.85539] [av. Q 2.78758]\n",
      "[epoch  193/500] [iter   72761] [loss 0.02757] [av. R 0.87871] [av. Q 2.78312]\n",
      "[epoch  194/500] [iter   73138] [loss 0.02714] [av. R 0.85554] [av. Q 2.78539]\n",
      "[epoch  195/500] [iter   73515] [loss 0.03173] [av. R 0.85564] [av. Q 2.78081]\n",
      "[epoch  196/500] [iter   73892] [loss 0.02403] [av. R 0.87976] [av. Q 2.78496]\n",
      "[epoch  197/500] [iter   74269] [loss 0.03753] [av. R 0.86004] [av. Q 2.78638]\n",
      "[epoch  198/500] [iter   74646] [loss 0.02386] [av. R 0.87341] [av. Q 2.78418]\n",
      "[epoch  199/500] [iter   75023] [loss 0.03006] [av. R 0.86572] [av. Q 2.78602]\n",
      "Copying Q weights\n",
      "[epoch  200/500] [iter   75400] [loss 0.03256] [av. R 0.87293] [av. Q 2.80799]\n",
      "[epoch  201/500] [iter   75777] [loss 0.02887] [av. R 0.86584] [av. Q 2.81502]\n",
      "[epoch  202/500] [iter   76154] [loss 0.02461] [av. R 0.89126] [av. Q 2.81711]\n",
      "[epoch  203/500] [iter   76531] [loss 0.02759] [av. R 0.89531] [av. Q 2.81176]\n",
      "[epoch  204/500] [iter   76908] [loss 0.03245] [av. R 0.85718] [av. Q 2.81595]\n",
      "[epoch  205/500] [iter   77285] [loss 0.02525] [av. R 0.86645] [av. Q 2.81840]\n",
      "[epoch  206/500] [iter   77662] [loss 0.03463] [av. R 0.84335] [av. Q 2.80926]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch  207/500] [iter   78039] [loss 0.02381] [av. R 0.87321] [av. Q 2.81417]\n",
      "[epoch  208/500] [iter   78416] [loss 0.02617] [av. R 0.87029] [av. Q 2.80967]\n",
      "[epoch  209/500] [iter   78793] [loss 0.02556] [av. R 0.86274] [av. Q 2.81589]\n",
      "[epoch  210/500] [iter   79170] [loss 0.02852] [av. R 0.88675] [av. Q 2.81117]\n",
      "[epoch  211/500] [iter   79547] [loss 0.02414] [av. R 0.88440] [av. Q 2.81131]\n",
      "[epoch  212/500] [iter   79924] [loss 0.02596] [av. R 0.86274] [av. Q 2.81589]\n",
      "[epoch  213/500] [iter   80301] [loss 0.03258] [av. R 0.86937] [av. Q 2.80881]\n",
      "[epoch  214/500] [iter   80678] [loss 0.02468] [av. R 0.86192] [av. Q 2.81126]\n",
      "[epoch  215/500] [iter   81055] [loss 0.03064] [av. R 0.84349] [av. Q 2.80906]\n",
      "[epoch  216/500] [iter   81432] [loss 0.02030] [av. R 0.88687] [av. Q 2.81732]\n",
      "[epoch  217/500] [iter   81809] [loss 0.02603] [av. R 0.87029] [av. Q 2.80967]\n",
      "[epoch  218/500] [iter   82186] [loss 0.02997] [av. R 0.85049] [av. Q 2.81724]\n",
      "[epoch  219/500] [iter   82563] [loss 0.02651] [av. R 0.87506] [av. Q 2.81835]\n",
      "Copying Q weights\n",
      "[epoch  220/500] [iter   82940] [loss 0.02668] [av. R 0.87724] [av. Q 2.84187]\n",
      "[epoch  221/500] [iter   83317] [loss 0.03006] [av. R 0.90378] [av. Q 2.84174]\n",
      "[epoch  222/500] [iter   83694] [loss 0.01869] [av. R 0.87877] [av. Q 2.83833]\n",
      "[epoch  223/500] [iter   84071] [loss 0.02620] [av. R 0.88216] [av. Q 2.84198]\n",
      "[epoch  224/500] [iter   84448] [loss 0.03310] [av. R 0.84855] [av. Q 2.83924]\n",
      "[epoch  225/500] [iter   84825] [loss 0.02131] [av. R 0.88636] [av. Q 2.83543]\n",
      "[epoch  226/500] [iter   85202] [loss 0.02387] [av. R 0.87365] [av. Q 2.84154]\n",
      "[epoch  227/500] [iter   85579] [loss 0.02533] [av. R 0.86623] [av. Q 2.83582]\n",
      "[epoch  228/500] [iter   85956] [loss 0.02786] [av. R 0.87181] [av. Q 2.83625]\n",
      "[epoch  229/500] [iter   86333] [loss 0.03073] [av. R 0.85921] [av. Q 2.83529]\n",
      "[epoch  230/500] [iter   86710] [loss 0.02236] [av. R 0.87844] [av. Q 2.83949]\n",
      "[epoch  231/500] [iter   87087] [loss 0.02958] [av. R 0.87036] [av. Q 2.83708]\n",
      "[epoch  232/500] [iter   87464] [loss 0.02694] [av. R 0.86206] [av. Q 2.84009]\n",
      "[epoch  233/500] [iter   87841] [loss 0.02471] [av. R 0.89126] [av. Q 2.84166]\n",
      "[epoch  234/500] [iter   88218] [loss 0.03013] [av. R 0.84855] [av. Q 2.83909]\n",
      "[epoch  235/500] [iter   88595] [loss 0.02813] [av. R 0.86481] [av. Q 2.83577]\n",
      "[epoch  236/500] [iter   88972] [loss 0.02916] [av. R 0.87249] [av. Q 2.84059]\n",
      "[epoch  237/500] [iter   89349] [loss 0.02316] [av. R 0.87792] [av. Q 2.83457]\n",
      "[epoch  238/500] [iter   89726] [loss 0.02794] [av. R 0.90268] [av. Q 2.84013]\n",
      "[epoch  239/500] [iter   90103] [loss 0.02467] [av. R 0.87669] [av. Q 2.83839]\n",
      "Copying Q weights\n",
      "[epoch  240/500] [iter   90480] [loss 0.02095] [av. R 0.89875] [av. Q 2.85884]\n",
      "[epoch  241/500] [iter   90857] [loss 0.02890] [av. R 0.86470] [av. Q 2.85808]\n",
      "[epoch  242/500] [iter   91234] [loss 0.02741] [av. R 0.91392] [av. Q 2.85958]\n",
      "[epoch  243/500] [iter   91611] [loss 0.03050] [av. R 0.84349] [av. Q 2.85993]\n",
      "[epoch  244/500] [iter   91988] [loss 0.02469] [av. R 0.87196] [av. Q 2.86664]\n",
      "[epoch  245/500] [iter   92365] [loss 0.02402] [av. R 0.88749] [av. Q 2.86678]\n",
      "[epoch  246/500] [iter   92742] [loss 0.02390] [av. R 0.86477] [av. Q 2.85970]\n",
      "[epoch  247/500] [iter   93119] [loss 0.02785] [av. R 0.86831] [av. Q 2.85831]\n",
      "[epoch  248/500] [iter   93496] [loss 0.02674] [av. R 0.91392] [av. Q 2.85958]\n",
      "[epoch  249/500] [iter   93873] [loss 0.02641] [av. R 0.89478] [av. Q 2.85948]\n",
      "[epoch  250/500] [iter   94250] [loss 0.03180] [av. R 0.89167] [av. Q 2.86822]\n",
      "[epoch  251/500] [iter   94627] [loss 0.03671] [av. R 0.88222] [av. Q 2.86200]\n",
      "[epoch  252/500] [iter   95004] [loss 0.02825] [av. R 0.86520] [av. Q 2.86090]\n",
      "[epoch  253/500] [iter   95381] [loss 0.02277] [av. R 0.88093] [av. Q 2.86058]\n",
      "[epoch  254/500] [iter   95758] [loss 0.03253] [av. R 0.89005] [av. Q 2.85942]\n",
      "[epoch  255/500] [iter   96135] [loss 0.02416] [av. R 0.85657] [av. Q 2.85981]\n",
      "[epoch  256/500] [iter   96512] [loss 0.02732] [av. R 0.85554] [av. Q 2.86012]\n",
      "[epoch  257/500] [iter   96889] [loss 0.02688] [av. R 0.87456] [av. Q 2.86184]\n",
      "[epoch  258/500] [iter   97266] [loss 0.02514] [av. R 0.85526] [av. Q 2.86264]\n",
      "[epoch  259/500] [iter   97643] [loss 0.03270] [av. R 0.84220] [av. Q 2.85786]\n",
      "Copying Q weights\n",
      "[epoch  260/500] [iter   98020] [loss 0.02918] [av. R 0.88078] [av. Q 2.87373]\n",
      "[epoch  261/500] [iter   98397] [loss 0.02579] [av. R 0.85298] [av. Q 2.87450]\n",
      "[epoch  262/500] [iter   98774] [loss 0.02380] [av. R 0.87321] [av. Q 2.87591]\n",
      "[epoch  263/500] [iter   99151] [loss 0.02117] [av. R 0.86756] [av. Q 2.87855]\n",
      "[epoch  264/500] [iter   99528] [loss 0.01954] [av. R 0.88365] [av. Q 2.87208]\n",
      "[epoch  265/500] [iter   99905] [loss 0.02994] [av. R 0.84993] [av. Q 2.87875]\n",
      "[epoch  266/500] [iter  100282] [loss 0.02902] [av. R 0.88297] [av. Q 2.88006]\n",
      "[epoch  267/500] [iter  100659] [loss 0.03363] [av. R 0.89599] [av. Q 2.86999]\n",
      "[epoch  268/500] [iter  101036] [loss 0.03307] [av. R 0.86513] [av. Q 2.87382]\n",
      "[epoch  269/500] [iter  101413] [loss 0.02986] [av. R 0.84554] [av. Q 2.86877]\n",
      "[epoch  270/500] [iter  101790] [loss 0.02584] [av. R 0.88584] [av. Q 2.87611]\n",
      "[epoch  271/500] [iter  102167] [loss 0.02457] [av. R 0.87196] [av. Q 2.88053]\n",
      "[epoch  272/500] [iter  102544] [loss 0.03435] [av. R 0.84335] [av. Q 2.87142]\n",
      "[epoch  273/500] [iter  102921] [loss 0.03242] [av. R 0.85539] [av. Q 2.87517]\n",
      "[epoch  274/500] [iter  103298] [loss 0.02291] [av. R 0.87140] [av. Q 2.87299]\n",
      "[epoch  275/500] [iter  103675] [loss 0.02587] [av. R 0.88110] [av. Q 2.87697]\n",
      "[epoch  276/500] [iter  104052] [loss 0.02293] [av. R 0.89353] [av. Q 2.87300]\n",
      "[epoch  277/500] [iter  104429] [loss 0.02445] [av. R 0.89057] [av. Q 2.87226]\n",
      "[epoch  278/500] [iter  104806] [loss 0.02229] [av. R 0.88527] [av. Q 2.87338]\n",
      "[epoch  279/500] [iter  105183] [loss 0.02855] [av. R 0.89343] [av. Q 2.87005]\n",
      "Copying Q weights\n",
      "[epoch  280/500] [iter  105560] [loss 0.02834] [av. R 0.85679] [av. Q 2.89357]\n",
      "[epoch  281/500] [iter  105937] [loss 0.02858] [av. R 0.86407] [av. Q 2.88694]\n",
      "[epoch  282/500] [iter  106314] [loss 0.02139] [av. R 0.86756] [av. Q 2.89424]\n",
      "[epoch  283/500] [iter  106691] [loss 0.02999] [av. R 0.86217] [av. Q 2.89426]\n",
      "[epoch  284/500] [iter  107068] [loss 0.02818] [av. R 0.86407] [av. Q 2.88694]\n",
      "[epoch  285/500] [iter  107445] [loss 0.03243] [av. R 0.84220] [av. Q 2.88909]\n",
      "[epoch  286/500] [iter  107822] [loss 0.02929] [av. R 0.87445] [av. Q 2.88936]\n",
      "[epoch  287/500] [iter  108199] [loss 0.02771] [av. R 0.87181] [av. Q 2.88696]\n",
      "[epoch  288/500] [iter  108576] [loss 0.04090] [av. R 0.86262] [av. Q 2.89034]\n",
      "[epoch  289/500] [iter  108953] [loss 0.02782] [av. R 0.89133] [av. Q 2.89636]\n",
      "[epoch  290/500] [iter  109330] [loss 0.02660] [av. R 0.91392] [av. Q 2.89010]\n",
      "[epoch  291/500] [iter  109707] [loss 0.02616] [av. R 0.85047] [av. Q 2.88854]\n",
      "[epoch  292/500] [iter  110084] [loss 0.02680] [av. R 0.89693] [av. Q 2.89438]\n",
      "[epoch  293/500] [iter  110461] [loss 0.02924] [av. R 0.85332] [av. Q 2.88872]\n",
      "[epoch  294/500] [iter  110838] [loss 0.02642] [av. R 0.85047] [av. Q 2.88854]\n",
      "[epoch  295/500] [iter  111215] [loss 0.02396] [av. R 0.88440] [av. Q 2.89115]\n",
      "[epoch  296/500] [iter  111592] [loss 0.02459] [av. R 0.89101] [av. Q 2.89043]\n",
      "[epoch  297/500] [iter  111969] [loss 0.03071] [av. R 0.85921] [av. Q 2.88996]\n",
      "[epoch  298/500] [iter  112346] [loss 0.02912] [av. R 0.88078] [av. Q 2.89056]\n",
      "[epoch  299/500] [iter  112723] [loss 0.02613] [av. R 0.88503] [av. Q 2.89136]\n",
      "Copying Q weights\n",
      "[epoch  300/500] [iter  113100] [loss 0.02837] [av. R 0.89343] [av. Q 2.88306]\n",
      "[epoch  301/500] [iter  113477] [loss 0.03023] [av. R 0.89974] [av. Q 2.88444]\n",
      "[epoch  302/500] [iter  113854] [loss 0.03066] [av. R 0.86204] [av. Q 2.88610]\n",
      "[epoch  303/500] [iter  114231] [loss 0.02637] [av. R 0.86586] [av. Q 2.88288]\n",
      "[epoch  304/500] [iter  114608] [loss 0.03140] [av. R 0.87369] [av. Q 2.88605]\n",
      "[epoch  305/500] [iter  114985] [loss 0.02412] [av. R 0.86072] [av. Q 2.89127]\n",
      "[epoch  306/500] [iter  115362] [loss 0.03368] [av. R 0.87152] [av. Q 2.89090]\n",
      "[epoch  307/500] [iter  115739] [loss 0.02282] [av. R 0.86007] [av. Q 2.88676]\n",
      "[epoch  308/500] [iter  116116] [loss 0.02377] [av. R 0.85019] [av. Q 2.88618]\n",
      "[epoch  309/500] [iter  116493] [loss 0.02974] [av. R 0.85705] [av. Q 2.88990]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch  310/500] [iter  116870] [loss 0.02501] [av. R 0.90166] [av. Q 2.88715]\n",
      "[epoch  311/500] [iter  117247] [loss 0.03439] [av. R 0.85294] [av. Q 2.88706]\n",
      "[epoch  312/500] [iter  117624] [loss 0.02563] [av. R 0.89996] [av. Q 2.88947]\n",
      "[epoch  313/500] [iter  118001] [loss 0.02640] [av. R 0.88375] [av. Q 2.89199]\n",
      "[epoch  314/500] [iter  118378] [loss 0.02443] [av. R 0.87196] [av. Q 2.89075]\n",
      "[epoch  315/500] [iter  118755] [loss 0.02533] [av. R 0.85529] [av. Q 2.88270]\n",
      "[epoch  316/500] [iter  119132] [loss 0.02864] [av. R 0.86420] [av. Q 2.89152]\n",
      "[epoch  317/500] [iter  119509] [loss 0.03298] [av. R 0.88352] [av. Q 2.88888]\n",
      "[epoch  318/500] [iter  119886] [loss 0.02469] [av. R 0.86546] [av. Q 2.88451]\n",
      "[epoch  319/500] [iter  120263] [loss 0.02706] [av. R 0.88004] [av. Q 2.88950]\n",
      "Copying Q weights\n",
      "[epoch  320/500] [iter  120640] [loss 0.02401] [av. R 0.86716] [av. Q 2.88869]\n",
      "[epoch  321/500] [iter  121017] [loss 0.02129] [av. R 0.88636] [av. Q 2.89045]\n",
      "[epoch  322/500] [iter  121394] [loss 0.02512] [av. R 0.85526] [av. Q 2.89294]\n",
      "[epoch  323/500] [iter  121771] [loss 0.02387] [av. R 0.91800] [av. Q 2.88948]\n",
      "[epoch  324/500] [iter  122148] [loss 0.03366] [av. R 0.89599] [av. Q 2.88757]\n",
      "[epoch  325/500] [iter  122525] [loss 0.02576] [av. R 0.88216] [av. Q 2.89400]\n",
      "[epoch  326/500] [iter  122902] [loss 0.02610] [av. R 0.87086] [av. Q 2.89174]\n",
      "[epoch  327/500] [iter  123279] [loss 0.02482] [av. R 0.89529] [av. Q 2.89248]\n",
      "[epoch  328/500] [iter  123656] [loss 0.02607] [av. R 0.85529] [av. Q 2.88744]\n",
      "[epoch  329/500] [iter  124033] [loss 0.03180] [av. R 0.88489] [av. Q 2.89116]\n",
      "[epoch  330/500] [iter  124410] [loss 0.02911] [av. R 0.85509] [av. Q 2.89231]\n",
      "[epoch  331/500] [iter  124787] [loss 0.02614] [av. R 0.87029] [av. Q 2.89109]\n",
      "[epoch  332/500] [iter  125164] [loss 0.02991] [av. R 0.87049] [av. Q 2.89314]\n",
      "[epoch  333/500] [iter  125541] [loss 0.02662] [av. R 0.87724] [av. Q 2.89264]\n",
      "[epoch  334/500] [iter  125918] [loss 0.03429] [av. R 0.85294] [av. Q 2.89219]\n",
      "[epoch  335/500] [iter  126295] [loss 0.02932] [av. R 0.86627] [av. Q 2.89244]\n",
      "[epoch  336/500] [iter  126672] [loss 0.02370] [av. R 0.87811] [av. Q 2.88986]\n",
      "[epoch  337/500] [iter  127049] [loss 0.03057] [av. R 0.89386] [av. Q 2.89118]\n",
      "[epoch  338/500] [iter  127426] [loss 0.02588] [av. R 0.85298] [av. Q 2.89052]\n",
      "[epoch  339/500] [iter  127803] [loss 0.02532] [av. R 0.84012] [av. Q 2.89054]\n",
      "Copying Q weights\n",
      "[epoch  340/500] [iter  128180] [loss 0.02192] [av. R 0.89160] [av. Q 2.89110]\n",
      "[epoch  341/500] [iter  128557] [loss 0.02299] [av. R 0.85087] [av. Q 2.88572]\n",
      "[epoch  342/500] [iter  128934] [loss 0.03282] [av. R 0.86513] [av. Q 2.88983]\n",
      "[epoch  343/500] [iter  129311] [loss 0.02960] [av. R 0.86695] [av. Q 2.88862]\n",
      "[epoch  344/500] [iter  129688] [loss 0.02800] [av. R 0.85679] [av. Q 2.89223]\n",
      "[epoch  345/500] [iter  130065] [loss 0.03112] [av. R 0.87216] [av. Q 2.89795]\n",
      "[epoch  346/500] [iter  130442] [loss 0.02970] [av. R 0.87915] [av. Q 2.88851]\n",
      "[epoch  347/500] [iter  130819] [loss 0.03428] [av. R 0.85294] [av. Q 2.89087]\n",
      "[epoch  348/500] [iter  131196] [loss 0.02921] [av. R 0.86627] [av. Q 2.89199]\n",
      "[epoch  349/500] [iter  131573] [loss 0.02387] [av. R 0.87798] [av. Q 2.88944]\n",
      "[epoch  350/500] [iter  131950] [loss 0.03000] [av. R 0.86676] [av. Q 2.89120]\n",
      "[epoch  351/500] [iter  132327] [loss 0.03328] [av. R 0.86231] [av. Q 2.89178]\n",
      "[epoch  352/500] [iter  132704] [loss 0.01945] [av. R 0.88826] [av. Q 2.88867]\n",
      "[epoch  353/500] [iter  133081] [loss 0.02932] [av. R 0.86627] [av. Q 2.89594]\n",
      "[epoch  354/500] [iter  133458] [loss 0.02406] [av. R 0.88201] [av. Q 2.88697]\n",
      "[epoch  355/500] [iter  133835] [loss 0.02556] [av. R 0.87875] [av. Q 2.88896]\n",
      "[epoch  356/500] [iter  134212] [loss 0.02029] [av. R 0.87763] [av. Q 2.88665]\n",
      "[epoch  357/500] [iter  134589] [loss 0.02561] [av. R 0.87875] [av. Q 2.88896]\n",
      "[epoch  358/500] [iter  134966] [loss 0.02692] [av. R 0.84147] [av. Q 2.88867]\n",
      "[epoch  359/500] [iter  135343] [loss 0.03522] [av. R 0.83726] [av. Q 2.88950]\n",
      "Copying Q weights\n",
      "[epoch  360/500] [iter  135720] [loss 0.03525] [av. R 0.86441] [av. Q 2.90004]\n",
      "[epoch  361/500] [iter  136097] [loss 0.03098] [av. R 0.83582] [av. Q 2.90176]\n",
      "[epoch  362/500] [iter  136474] [loss 0.01993] [av. R 0.88774] [av. Q 2.89714]\n",
      "[epoch  363/500] [iter  136851] [loss 0.02854] [av. R 0.86840] [av. Q 2.89932]\n",
      "[epoch  364/500] [iter  137228] [loss 0.02577] [av. R 0.85727] [av. Q 2.89699]\n",
      "[epoch  365/500] [iter  137605] [loss 0.02806] [av. R 0.83798] [av. Q 2.89632]\n",
      "[epoch  366/500] [iter  137982] [loss 0.02587] [av. R 0.85727] [av. Q 2.89699]\n",
      "[epoch  367/500] [iter  138359] [loss 0.03454] [av. R 0.87161] [av. Q 2.89434]\n",
      "[epoch  368/500] [iter  138736] [loss 0.02927] [av. R 0.85509] [av. Q 2.89843]\n",
      "[epoch  369/500] [iter  139113] [loss 0.02716] [av. R 0.89291] [av. Q 2.89593]\n",
      "[epoch  370/500] [iter  139490] [loss 0.02827] [av. R 0.85902] [av. Q 2.89951]\n",
      "[epoch  371/500] [iter  139867] [loss 0.03041] [av. R 0.84348] [av. Q 2.90072]\n",
      "[epoch  372/500] [iter  140244] [loss 0.03281] [av. R 0.86513] [av. Q 2.89701]\n",
      "[epoch  373/500] [iter  140621] [loss 0.02951] [av. R 0.87915] [av. Q 2.89568]\n",
      "[epoch  374/500] [iter  140998] [loss 0.02960] [av. R 0.90378] [av. Q 2.89741]\n",
      "[epoch  375/500] [iter  141375] [loss 0.02027] [av. R 0.88687] [av. Q 2.89970]\n",
      "[epoch  376/500] [iter  141752] [loss 0.02417] [av. R 0.85816] [av. Q 2.89818]\n",
      "[epoch  377/500] [iter  142129] [loss 0.02721] [av. R 0.85099] [av. Q 2.89863]\n",
      "[epoch  378/500] [iter  142506] [loss 0.02294] [av. R 0.89628] [av. Q 2.90079]\n",
      "[epoch  379/500] [iter  142883] [loss 0.02989] [av. R 0.86917] [av. Q 2.90034]\n",
      "Copying Q weights\n",
      "[epoch  380/500] [iter  143260] [loss 0.02941] [av. R 0.86725] [av. Q 2.89243]\n",
      "[epoch  381/500] [iter  143637] [loss 0.01961] [av. R 0.88365] [av. Q 2.89331]\n",
      "[epoch  382/500] [iter  144014] [loss 0.03595] [av. R 0.85373] [av. Q 2.89628]\n",
      "[epoch  383/500] [iter  144391] [loss 0.02879] [av. R 0.88870] [av. Q 2.89019]\n",
      "[epoch  384/500] [iter  144768] [loss 0.02714] [av. R 0.89693] [av. Q 2.89608]\n",
      "[epoch  385/500] [iter  145145] [loss 0.02917] [av. R 0.86627] [av. Q 2.89677]\n",
      "[epoch  386/500] [iter  145522] [loss 0.04099] [av. R 0.86262] [av. Q 2.89549]\n",
      "[epoch  387/500] [iter  145899] [loss 0.03207] [av. R 0.87875] [av. Q 2.89523]\n",
      "[epoch  388/500] [iter  146276] [loss 0.02250] [av. R 0.88527] [av. Q 2.89416]\n",
      "[epoch  389/500] [iter  146653] [loss 0.02740] [av. R 0.86720] [av. Q 2.89250]\n",
      "[epoch  390/500] [iter  147030] [loss 0.02924] [av. R 0.87173] [av. Q 2.89422]\n",
      "[epoch  391/500] [iter  147407] [loss 0.02600] [av. R 0.88503] [av. Q 2.89447]\n",
      "[epoch  392/500] [iter  147784] [loss 0.03056] [av. R 0.85893] [av. Q 2.89290]\n",
      "[epoch  393/500] [iter  148161] [loss 0.02481] [av. R 0.89080] [av. Q 2.89244]\n",
      "[epoch  394/500] [iter  148538] [loss 0.02795] [av. R 0.84366] [av. Q 2.89376]\n",
      "[epoch  395/500] [iter  148915] [loss 0.02558] [av. R 0.87596] [av. Q 2.89442]\n",
      "[epoch  396/500] [iter  149292] [loss 0.02949] [av. R 0.85705] [av. Q 2.89675]\n",
      "[epoch  397/500] [iter  149669] [loss 0.02432] [av. R 0.86192] [av. Q 2.89272]\n",
      "[epoch  398/500] [iter  150046] [loss 0.02869] [av. R 0.87445] [av. Q 2.89254]\n",
      "[epoch  399/500] [iter  150423] [loss 0.02346] [av. R 0.87365] [av. Q 2.89617]\n",
      "Copying Q weights\n",
      "[epoch  400/500] [iter  150800] [loss 0.02882] [av. R 0.86008] [av. Q 2.90240]\n",
      "[epoch  401/500] [iter  151177] [loss 0.02728] [av. R 0.89133] [av. Q 2.90197]\n",
      "[epoch  402/500] [iter  151554] [loss 0.02458] [av. R 0.89101] [av. Q 2.89860]\n",
      "[epoch  403/500] [iter  151931] [loss 0.03310] [av. R 0.85536] [av. Q 2.89498]\n",
      "[epoch  404/500] [iter  152308] [loss 0.02696] [av. R 0.88790] [av. Q 2.90024]\n",
      "[epoch  405/500] [iter  152685] [loss 0.02463] [av. R 0.87669] [av. Q 2.89991]\n",
      "[epoch  406/500] [iter  153062] [loss 0.02450] [av. R 0.88589] [av. Q 2.89734]\n",
      "[epoch  407/500] [iter  153439] [loss 0.02693] [av. R 0.86444] [av. Q 2.89725]\n",
      "[epoch  408/500] [iter  153816] [loss 0.02817] [av. R 0.86519] [av. Q 2.90193]\n",
      "[epoch  409/500] [iter  154193] [loss 0.02426] [av. R 0.86929] [av. Q 2.89933]\n",
      "[epoch  410/500] [iter  154570] [loss 0.02958] [av. R 0.84993] [av. Q 2.90167]\n",
      "[epoch  411/500] [iter  154947] [loss 0.02955] [av. R 0.85705] [av. Q 2.90184]\n",
      "[epoch  412/500] [iter  155324] [loss 0.03294] [av. R 0.88352] [av. Q 2.89968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch  413/500] [iter  155701] [loss 0.02929] [av. R 0.86217] [av. Q 2.90040]\n",
      "[epoch  414/500] [iter  156078] [loss 0.02584] [av. R 0.86359] [av. Q 2.90064]\n",
      "[epoch  415/500] [iter  156455] [loss 0.02670] [av. R 0.88654] [av. Q 2.89761]\n",
      "[epoch  416/500] [iter  156832] [loss 0.02620] [av. R 0.89478] [av. Q 2.89663]\n",
      "[epoch  417/500] [iter  157209] [loss 0.02902] [av. R 0.85571] [av. Q 2.89986]\n",
      "[epoch  418/500] [iter  157586] [loss 0.02812] [av. R 0.86519] [av. Q 2.90193]\n",
      "[epoch  419/500] [iter  157963] [loss 0.02977] [av. R 0.85705] [av. Q 2.90184]\n",
      "Copying Q weights\n",
      "[epoch  420/500] [iter  158340] [loss 0.03598] [av. R 0.86210] [av. Q 2.90311]\n",
      "[epoch  421/500] [iter  158717] [loss 0.02772] [av. R 0.86636] [av. Q 2.90050]\n",
      "[epoch  422/500] [iter  159094] [loss 0.02827] [av. R 0.85902] [av. Q 2.90415]\n",
      "[epoch  423/500] [iter  159471] [loss 0.02133] [av. R 0.87037] [av. Q 2.90056]\n",
      "[epoch  424/500] [iter  159848] [loss 0.02676] [av. R 0.87724] [av. Q 2.90129]\n",
      "[epoch  425/500] [iter  160225] [loss 0.03343] [av. R 0.86563] [av. Q 2.90140]\n",
      "[epoch  426/500] [iter  160602] [loss 0.03139] [av. R 0.85513] [av. Q 2.90162]\n",
      "[epoch  427/500] [iter  160979] [loss 0.03314] [av. R 0.84841] [av. Q 2.90678]\n",
      "[epoch  428/500] [iter  161356] [loss 0.04094] [av. R 0.86262] [av. Q 2.90402]\n",
      "[epoch  429/500] [iter  161733] [loss 0.02002] [av. R 0.85845] [av. Q 2.90393]\n",
      "[epoch  430/500] [iter  162110] [loss 0.02705] [av. R 0.85717] [av. Q 2.90309]\n",
      "[epoch  431/500] [iter  162487] [loss 0.02840] [av. R 0.85543] [av. Q 2.90024]\n",
      "[epoch  432/500] [iter  162864] [loss 0.02253] [av. R 0.87015] [av. Q 2.89907]\n",
      "[epoch  433/500] [iter  163241] [loss 0.02964] [av. R 0.86917] [av. Q 2.90653]\n",
      "[epoch  434/500] [iter  163618] [loss 0.02858] [av. R 0.87445] [av. Q 2.90120]\n",
      "[epoch  435/500] [iter  163995] [loss 0.02685] [av. R 0.88038] [av. Q 2.90275]\n",
      "[epoch  436/500] [iter  164372] [loss 0.02613] [av. R 0.86616] [av. Q 2.90032]\n",
      "[epoch  437/500] [iter  164749] [loss 0.02426] [av. R 0.89126] [av. Q 2.90171]\n",
      "[epoch  438/500] [iter  165126] [loss 0.02394] [av. R 0.85816] [av. Q 2.90545]\n",
      "[epoch  439/500] [iter  165503] [loss 0.03310] [av. R 0.85536] [av. Q 2.89862]\n",
      "Copying Q weights\n",
      "[epoch  440/500] [iter  165880] [loss 0.02441] [av. R 0.85657] [av. Q 2.90391]\n",
      "[epoch  441/500] [iter  166257] [loss 0.02471] [av. R 0.85055] [av. Q 2.90576]\n",
      "[epoch  442/500] [iter  166634] [loss 0.03200] [av. R 0.87875] [av. Q 2.90487]\n",
      "[epoch  443/500] [iter  167011] [loss 0.02031] [av. R 0.87763] [av. Q 2.89692]\n",
      "[epoch  444/500] [iter  167388] [loss 0.02716] [av. R 0.85631] [av. Q 2.90740]\n",
      "[epoch  445/500] [iter  167765] [loss 0.03317] [av. R 0.85536] [av. Q 2.89937]\n",
      "[epoch  446/500] [iter  168142] [loss 0.03078] [av. R 0.89167] [av. Q 2.90944]\n",
      "[epoch  447/500] [iter  168519] [loss 0.02895] [av. R 0.88156] [av. Q 2.90176]\n",
      "[epoch  448/500] [iter  168896] [loss 0.02381] [av. R 0.85184] [av. Q 2.90678]\n",
      "[epoch  449/500] [iter  169273] [loss 0.02266] [av. R 0.88122] [av. Q 2.90301]\n",
      "[epoch  450/500] [iter  169650] [loss 0.03058] [av. R 0.89974] [av. Q 2.90233]\n",
      "[epoch  451/500] [iter  170027] [loss 0.03186] [av. R 0.88322] [av. Q 2.90272]\n",
      "[epoch  452/500] [iter  170404] [loss 0.03171] [av. R 0.85131] [av. Q 2.90506]\n",
      "[epoch  453/500] [iter  170781] [loss 0.02855] [av. R 0.86420] [av. Q 2.90348]\n",
      "[epoch  454/500] [iter  171158] [loss 0.02627] [av. R 0.86586] [av. Q 2.89957]\n",
      "[epoch  455/500] [iter  171535] [loss 0.02810] [av. R 0.86470] [av. Q 2.90120]\n",
      "[epoch  456/500] [iter  171912] [loss 0.02238] [av. R 0.90008] [av. Q 2.89985]\n",
      "[epoch  457/500] [iter  172289] [loss 0.02758] [av. R 0.85136] [av. Q 2.90465]\n",
      "[epoch  458/500] [iter  172666] [loss 0.02143] [av. R 0.87037] [av. Q 2.90030]\n",
      "[epoch  459/500] [iter  173043] [loss 0.03318] [av. R 0.84841] [av. Q 2.90752]\n",
      "Copying Q weights\n",
      "[epoch  460/500] [iter  173420] [loss 0.02909] [av. R 0.87036] [av. Q 2.89578]\n",
      "[epoch  461/500] [iter  173797] [loss 0.02256] [av. R 0.87716] [av. Q 2.89892]\n",
      "[epoch  462/500] [iter  174174] [loss 0.02541] [av. R 0.89837] [av. Q 2.89927]\n",
      "[epoch  463/500] [iter  174551] [loss 0.02835] [av. R 0.86840] [av. Q 2.89675]\n",
      "[epoch  464/500] [iter  174928] [loss 0.02752] [av. R 0.87871] [av. Q 2.89387]\n",
      "[epoch  465/500] [iter  175305] [loss 0.03452] [av. R 0.87161] [av. Q 2.89529]\n",
      "[epoch  466/500] [iter  175682] [loss 0.02722] [av. R 0.87412] [av. Q 2.89442]\n",
      "[epoch  467/500] [iter  176059] [loss 0.02400] [av. R 0.87908] [av. Q 2.89473]\n",
      "[epoch  468/500] [iter  176436] [loss 0.02595] [av. R 0.89136] [av. Q 2.89687]\n",
      "[epoch  469/500] [iter  176813] [loss 0.03128] [av. R 0.87443] [av. Q 2.89940]\n",
      "[epoch  470/500] [iter  177190] [loss 0.03061] [av. R 0.87216] [av. Q 2.90250]\n",
      "[epoch  471/500] [iter  177567] [loss 0.02265] [av. R 0.88330] [av. Q 2.89987]\n",
      "[epoch  472/500] [iter  177944] [loss 0.02470] [av. R 0.87604] [av. Q 2.90176]\n",
      "[epoch  473/500] [iter  178321] [loss 0.03448] [av. R 0.87161] [av. Q 2.89529]\n",
      "[epoch  474/500] [iter  178698] [loss 0.02661] [av. R 0.87724] [av. Q 2.89745]\n",
      "[epoch  475/500] [iter  179075] [loss 0.03400] [av. R 0.86852] [av. Q 2.90098]\n",
      "[epoch  476/500] [iter  179452] [loss 0.02951] [av. R 0.84349] [av. Q 2.89640]\n",
      "[epoch  477/500] [iter  179829] [loss 0.02592] [av. R 0.86139] [av. Q 2.89525]\n",
      "[epoch  478/500] [iter  180206] [loss 0.02206] [av. R 0.85567] [av. Q 2.89719]\n",
      "[epoch  479/500] [iter  180583] [loss 0.02572] [av. R 0.86689] [av. Q 2.89495]\n",
      "Copying Q weights\n",
      "[epoch  480/500] [iter  180960] [loss 0.03025] [av. R 0.88349] [av. Q 2.89341]\n",
      "[epoch  481/500] [iter  181337] [loss 0.02492] [av. R 0.87622] [av. Q 2.89278]\n",
      "[epoch  482/500] [iter  181714] [loss 0.03126] [av. R 0.87443] [av. Q 2.89733]\n",
      "[epoch  483/500] [iter  182091] [loss 0.03050] [av. R 0.85893] [av. Q 2.89781]\n",
      "[epoch  484/500] [iter  182468] [loss 0.02664] [av. R 0.86902] [av. Q 2.89662]\n",
      "[epoch  485/500] [iter  182845] [loss 0.02705] [av. R 0.86040] [av. Q 2.89413]\n",
      "[epoch  486/500] [iter  183222] [loss 0.02396] [av. R 0.88440] [av. Q 2.89261]\n",
      "[epoch  487/500] [iter  183599] [loss 0.02386] [av. R 0.85816] [av. Q 2.89718]\n",
      "[epoch  488/500] [iter  183976] [loss 0.03016] [av. R 0.84873] [av. Q 2.89937]\n",
      "[epoch  489/500] [iter  184353] [loss 0.02404] [av. R 0.87976] [av. Q 2.89279]\n",
      "[epoch  490/500] [iter  184730] [loss 0.02514] [av. R 0.88389] [av. Q 2.89876]\n",
      "[epoch  491/500] [iter  185107] [loss 0.02896] [av. R 0.87098] [av. Q 2.89521]\n",
      "[epoch  492/500] [iter  185484] [loss 0.02788] [av. R 0.84366] [av. Q 2.89669]\n",
      "[epoch  493/500] [iter  185861] [loss 0.02253] [av. R 0.87716] [av. Q 2.89655]\n",
      "[epoch  494/500] [iter  186238] [loss 0.03498] [av. R 0.81679] [av. Q 2.89403]\n",
      "[epoch  495/500] [iter  186615] [loss 0.02546] [av. R 0.87875] [av. Q 2.89671]\n",
      "[epoch  496/500] [iter  186992] [loss 0.02233] [av. R 0.90008] [av. Q 2.89348]\n",
      "[epoch  497/500] [iter  187369] [loss 0.02667] [av. R 0.87724] [av. Q 2.89548]\n",
      "[epoch  498/500] [iter  187746] [loss 0.03331] [av. R 0.87097] [av. Q 2.89387]\n",
      "[epoch  499/500] [iter  188123] [loss 0.03344] [av. R 0.86231] [av. Q 2.89284]\n",
      "Copying Q weights\n",
      "[epoch  500/500] [iter  188500] [loss 0.02554] [av. R 0.87995] [av. Q 2.90209]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(libPreprocess)\n",
    "importlib.reload(libRewards)\n",
    "\n",
    "def runTraining():    \n",
    "    combinedStates  = pd.concat([game['expertStates']  for game in GAMES])\n",
    "    combinedActions = pd.concat([game['expertActions'] for game in GAMES])\n",
    "    \n",
    "    dataBatches, stateSz, actionSz = libPreprocess.dataToBatches(combinedStates, combinedActions, BATCH_SZ, includeRewards=True)\n",
    "    qModel1 = SAtoV_Model(stateSz, actionSz, DEVICE)\n",
    "    qModel2 = SAtoV_Model(stateSz, actionSz, DEVICE)\n",
    "    qModel2.load_state_dict(qModel1.state_dict())\n",
    "    qModel2.eval()\n",
    "    \n",
    "    train_behavioral_cloning(dataBatches, qModel1, qModel2)\n",
    "    #qModel1.save(\"dqn\")\n",
    "    return qModel1\n",
    "\n",
    "model = runTraining()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
