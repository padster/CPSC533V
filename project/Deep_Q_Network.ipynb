{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q Network\n",
    "\n",
    "Train a Q(s, a) function, using trajectories of (s, a, r, s', a', r', s'', ...) from matches.\n",
    "\n",
    "Using a memory of previous (s, a, r, s'), and double Q networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "EXPERT_PLAYER_IDX = 0\n",
    "USE_GPU = False\n",
    "\n",
    "GAMES = [{\"id\": gameID} for gameID in [\"noBoost1v1_1\", \"noBoost1v1_2\", \"noBoost1v1_3\"]]\n",
    "\n",
    "# NOTE: can't use __file__ in jupyter notebook unfortunately, so hard-code it insteadL\n",
    "ROOT_PROJECT_PATH = 'C:/Users/User/code/CPSC533V/project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "DEVICE = torch.device(\"cuda\" if USE_GPU else \"cpu\")\n",
    "\n",
    "# Load local reusable code within 'lib/'\n",
    "sys.path.append(ROOT_PROJECT_PATH)\n",
    "import lib.files as libFiles\n",
    "import lib.preprocess as libPreprocess\n",
    "import lib.rewards as libRewards\n",
    "from lib.SAtoVModel import SAtoV_Model\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess all replays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n",
      "\treplays\\noBoost1v1_1.replay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find field_of_view in camera settings for Sundown\n",
      "Could not find height in camera settings for Sundown\n",
      "Could not find pitch in camera settings for Sundown\n",
      "Could not find distance in camera settings for Sundown\n",
      "Could not find stiffness in camera settings for Sundown\n",
      "Could not find swivel_speed in camera settings for Sundown\n",
      "Could not find transition_speed in camera settings for Sundown\n",
      "D:/projects/carball\\carball\\controls\\rotations.py:87: RuntimeWarning: invalid value encountered in sign\n",
      "  rhs[1] / (T_p + np.sign(rhs[1]) * omega[1] * D_p),\n",
      "D:/projects/carball\\carball\\controls\\rotations.py:88: RuntimeWarning: invalid value encountered in sign\n",
      "  rhs[2] / (T_y - np.sign(rhs[2]) * omega[2] * D_y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 players loaded!\n",
      "\n",
      "Orange team:\n",
      "\tbot\n",
      "\n",
      "Blue team:\n",
      "\texpert\n",
      "\n",
      "12921 data points acquired\n",
      "====\n",
      "\n",
      "\n",
      "Game data from 'noBoost1v1_1' preprocessed.\n",
      "    ... clean data available at 'playerStates', 'playerActions' and 'ballStates' keys\n",
      "\n",
      "State and action maps for player expert\n",
      "(12921, 29) float64\n",
      "(12921, 3) object\n",
      "=======\n",
      "\n",
      "\n",
      "Loading...\n",
      "\treplays\\noBoost1v1_2.replay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find field_of_view in camera settings for Beast\n",
      "Could not find height in camera settings for Beast\n",
      "Could not find pitch in camera settings for Beast\n",
      "Could not find distance in camera settings for Beast\n",
      "Could not find stiffness in camera settings for Beast\n",
      "Could not find swivel_speed in camera settings for Beast\n",
      "Could not find transition_speed in camera settings for Beast\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 players loaded!\n",
      "\n",
      "Orange team:\n",
      "\tbot\n",
      "\n",
      "Blue team:\n",
      "\texpert\n",
      "\n",
      "12016 data points acquired\n",
      "====\n",
      "\n",
      "\n",
      "Game data from 'noBoost1v1_2' preprocessed.\n",
      "    ... clean data available at 'playerStates', 'playerActions' and 'ballStates' keys\n",
      "\n",
      "State and action maps for player expert\n",
      "(12016, 29) float64\n",
      "(12016, 3) object\n",
      "=======\n",
      "\n",
      "\n",
      "Loading...\n",
      "\treplays\\noBoost1v1_3.replay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find field_of_view in camera settings for Middy\n",
      "Could not find height in camera settings for Middy\n",
      "Could not find pitch in camera settings for Middy\n",
      "Could not find distance in camera settings for Middy\n",
      "Could not find stiffness in camera settings for Middy\n",
      "Could not find swivel_speed in camera settings for Middy\n",
      "Could not find transition_speed in camera settings for Middy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 players loaded!\n",
      "\n",
      "Orange team:\n",
      "\tbot\n",
      "\n",
      "Blue team:\n",
      "\texpert\n",
      "\n",
      "12682 data points acquired\n",
      "====\n",
      "\n",
      "\n",
      "Game data from 'noBoost1v1_3' preprocessed.\n",
      "    ... clean data available at 'playerStates', 'playerActions' and 'ballStates' keys\n",
      "\n",
      "State and action maps for player expert\n",
      "(12682, 29) float64\n",
      "(12682, 3) object\n",
      "=======\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for game in GAMES:\n",
    "    game['data'] = libFiles.parseReplayToGameData(game['id'])\n",
    "    libFiles.cleanAndDisplayGameData(game['data'])\n",
    "    \n",
    "    game['playerStates'], game['playerActions'] = [], []\n",
    "    for p in game['data'].players:\n",
    "        game['playerStates' ].append(libPreprocess.cleanPlayerStates( p.data    ))\n",
    "        game['playerActions'].append(libPreprocess.cleanPlayerActions(p.controls))\n",
    "    game['ballStates'] = libPreprocess.cleanBallStates(game['data'].ball)\n",
    "    print (\"Game data from '%s' preprocessed.\" % game['id'])\n",
    "    print (\"    ... clean data available at 'playerStates', 'playerActions' and 'ballStates' keys\\n\")\n",
    "    \n",
    "    game['expertStates'], game['expertActions'] = libPreprocess.stateAndActionsForPlayer(game, EXPERT_PLAYER_IDX)\n",
    "    print (\"State and action maps for player %s\" % game['data'].players[EXPERT_PLAYER_IDX].name)\n",
    "    print (game['expertStates'].values.shape, game['expertStates'].values.dtype)\n",
    "    print (game['expertActions'].values.shape, game['expertActions'].values.dtype)\n",
    "    print (\"=======\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_EPOCHS = 300\n",
    "BATCH_SZ = 100\n",
    "LOG_INTERVAL = 1000\n",
    "LEARNING_RATE = 0.00003\n",
    "REGULARIZER_WEIGHT = 3e-4\n",
    "GAMMA = 0.7\n",
    "Q_SWAP_EPOCHS = 20\n",
    "\n",
    "writer = SummaryWriter(filename_suffix=\"dqn\")\n",
    "\n",
    "\n",
    "def train_behavioral_cloning(dataBatches, thisQ, nextQ):   \n",
    "    # Adam optimizer usually a good default.\n",
    "    optimizer = torch.optim.Adam(thisQ.parameters(), lr=LEARNING_RATE, weight_decay=REGULARIZER_WEIGHT)\n",
    "    \n",
    "    # MSE loss\n",
    "    loss_function = torch.nn.MSELoss().to(DEVICE)\n",
    "\n",
    "    gradient_steps = 0\n",
    "\n",
    "    for epoch in range(1, TOTAL_EPOCHS + 1):\n",
    "        batchShuffled = random.sample(dataBatches, len(dataBatches))\n",
    "        lastLoss, lastAverageR, lastAverageQ = -1, -1, -1\n",
    "        for iteration, data in enumerate(batchShuffled):\n",
    "            data = {k: v.to(DEVICE) for k, v in data.items()}\n",
    "            saCombined = torch.cat((data['s'], data['a']), dim=1)\n",
    "            \n",
    "            maxQCalc = libRewards.bestQ(nextQ, data['sPrime'], returnAction=False)\n",
    "            y_j_torch = data['r'] + GAMMA * maxQCalc\n",
    "            y_pred = thisQ(saCombined)\n",
    "    \n",
    "            # Gradient descent on MSE loss between predicted and calculated Q\n",
    "            loss = loss_function(y_j_torch, y_pred)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if gradient_steps % LOG_INTERVAL == 0:\n",
    "                writer.add_scalar('loss', loss.item(), gradient_steps)\n",
    "            \n",
    "            gradient_steps += 1\n",
    "            \n",
    "            if iteration == len(batchShuffled) - 1:\n",
    "                lastLoss = loss.item()\n",
    "                lastAverageR = np.mean(data['r'].detach().numpy())\n",
    "                lastAverageQ = np.mean(maxQCalc)\n",
    "            \n",
    "        print ('[epoch {:4d}/{}] [iter {:7d}] [loss {:.5f}] [av. R {:.5f}] [av. Q {:.5f}]'.format(\n",
    "           epoch, TOTAL_EPOCHS, gradient_steps, lastLoss, lastAverageR, lastAverageQ)\n",
    "        )\n",
    "        \n",
    "        if (epoch + 1) % Q_SWAP_EPOCHS == 0:\n",
    "            nextQ.load_state_dict(thisQ.state_dict())\n",
    "            nextQ.eval()\n",
    "            print (\"Copying Q weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37619 rows, 29 state dim, 3 action dim, into 377 batches of size 100\n",
      "[epoch    1/300] [iter     377] [loss 0.82059] [av. R 0.87967] [av. Q 0.21608]\n",
      "[epoch    2/300] [iter     754] [loss 0.66440] [av. R 0.86693] [av. Q 0.21321]\n",
      "[epoch    3/300] [iter    1131] [loss 0.52452] [av. R 0.84589] [av. Q 0.21603]\n",
      "[epoch    4/300] [iter    1508] [loss 0.46243] [av. R 0.87347] [av. Q 0.22392]\n",
      "[epoch    5/300] [iter    1885] [loss 0.37066] [av. R 0.86981] [av. Q 0.21471]\n",
      "[epoch    6/300] [iter    2262] [loss 0.32905] [av. R 0.88221] [av. Q 0.22181]\n",
      "[epoch    7/300] [iter    2639] [loss 0.24929] [av. R 0.86284] [av. Q 0.21883]\n",
      "[epoch    8/300] [iter    3016] [loss 0.19997] [av. R 0.86284] [av. Q 0.21883]\n",
      "[epoch    9/300] [iter    3393] [loss 0.14913] [av. R 0.83955] [av. Q 0.21623]\n",
      "[epoch   10/300] [iter    3770] [loss 0.14165] [av. R 0.87774] [av. Q 0.21549]\n",
      "[epoch   11/300] [iter    4147] [loss 0.11263] [av. R 0.86946] [av. Q 0.21760]\n",
      "[epoch   12/300] [iter    4524] [loss 0.08587] [av. R 0.85320] [av. Q 0.21750]\n",
      "[epoch   13/300] [iter    4901] [loss 0.06723] [av. R 0.84554] [av. Q 0.21552]\n",
      "[epoch   14/300] [iter    5278] [loss 0.05859] [av. R 0.84132] [av. Q 0.21390]\n",
      "[epoch   15/300] [iter    5655] [loss 0.05243] [av. R 0.85510] [av. Q 0.21736]\n",
      "[epoch   16/300] [iter    6032] [loss 0.04466] [av. R 0.84141] [av. Q 0.21747]\n",
      "[epoch   17/300] [iter    6409] [loss 0.04493] [av. R 0.89414] [av. Q 0.22112]\n",
      "[epoch   18/300] [iter    6786] [loss 0.03702] [av. R 0.86121] [av. Q 0.22026]\n",
      "[epoch   19/300] [iter    7163] [loss 0.04024] [av. R 0.85729] [av. Q 0.21530]\n",
      "Copying Q weights\n",
      "[epoch   20/300] [iter    7540] [loss 0.34002] [av. R 0.86816] [av. Q 1.20840]\n",
      "[epoch   21/300] [iter    7917] [loss 0.28051] [av. R 0.88580] [av. Q 1.22911]\n",
      "[epoch   22/300] [iter    8294] [loss 0.19991] [av. R 0.89508] [av. Q 1.22306]\n",
      "[epoch   23/300] [iter    8671] [loss 0.14922] [av. R 0.88538] [av. Q 1.21366]\n",
      "[epoch   24/300] [iter    9048] [loss 0.10064] [av. R 0.83327] [av. Q 1.20362]\n",
      "[epoch   25/300] [iter    9425] [loss 0.08957] [av. R 0.89887] [av. Q 1.21157]\n",
      "[epoch   26/300] [iter    9802] [loss 0.06661] [av. R 0.87613] [av. Q 1.19327]\n",
      "[epoch   27/300] [iter   10179] [loss 0.04969] [av. R 0.85339] [av. Q 1.21455]\n",
      "[epoch   28/300] [iter   10556] [loss 0.04925] [av. R 0.85052] [av. Q 1.19847]\n",
      "[epoch   29/300] [iter   10933] [loss 0.03578] [av. R 0.86014] [av. Q 1.17997]\n",
      "[epoch   30/300] [iter   11310] [loss 0.04856] [av. R 0.89953] [av. Q 1.20635]\n",
      "[epoch   31/300] [iter   11687] [loss 0.04420] [av. R 0.85374] [av. Q 1.17672]\n",
      "[epoch   32/300] [iter   12064] [loss 0.03797] [av. R 0.89029] [av. Q 1.19205]\n",
      "[epoch   33/300] [iter   12441] [loss 0.04427] [av. R 0.87143] [av. Q 1.20906]\n",
      "[epoch   34/300] [iter   12818] [loss 0.03941] [av. R 0.87880] [av. Q 1.21625]\n",
      "[epoch   35/300] [iter   13195] [loss 0.03914] [av. R 0.87927] [av. Q 1.20124]\n",
      "[epoch   36/300] [iter   13572] [loss 0.03859] [av. R 0.87294] [av. Q 1.20008]\n",
      "[epoch   37/300] [iter   13949] [loss 0.03369] [av. R 0.84608] [av. Q 1.17221]\n",
      "[epoch   38/300] [iter   14326] [loss 0.03292] [av. R 0.87793] [av. Q 1.17456]\n",
      "[epoch   39/300] [iter   14703] [loss 0.04788] [av. R 0.85157] [av. Q 1.21505]\n",
      "Copying Q weights\n",
      "[epoch   40/300] [iter   15080] [loss 0.08688] [av. R 0.86430] [av. Q 1.81691]\n",
      "[epoch   41/300] [iter   15457] [loss 0.07411] [av. R 0.88180] [av. Q 1.82850]\n",
      "[epoch   42/300] [iter   15834] [loss 0.05061] [av. R 0.83273] [av. Q 1.83453]\n",
      "[epoch   43/300] [iter   16211] [loss 0.03667] [av. R 0.87618] [av. Q 1.81233]\n",
      "[epoch   44/300] [iter   16588] [loss 0.03743] [av. R 0.86203] [av. Q 1.80438]\n",
      "[epoch   45/300] [iter   16965] [loss 0.03401] [av. R 0.86246] [av. Q 1.79974]\n",
      "[epoch   46/300] [iter   17342] [loss 0.03602] [av. R 0.89087] [av. Q 1.82425]\n",
      "[epoch   47/300] [iter   17719] [loss 0.03311] [av. R 0.87993] [av. Q 1.80327]\n",
      "[epoch   48/300] [iter   18096] [loss 0.04718] [av. R 0.85918] [av. Q 1.82528]\n",
      "[epoch   49/300] [iter   18473] [loss 0.03497] [av. R 0.87613] [av. Q 1.81043]\n",
      "[epoch   50/300] [iter   18850] [loss 0.03272] [av. R 0.85701] [av. Q 1.80141]\n",
      "[epoch   51/300] [iter   19227] [loss 0.04898] [av. R 0.86635] [av. Q 1.80591]\n",
      "[epoch   52/300] [iter   19604] [loss 0.03807] [av. R 0.87880] [av. Q 1.82906]\n",
      "[epoch   53/300] [iter   19981] [loss 0.03386] [av. R 0.89401] [av. Q 1.82715]\n",
      "[epoch   54/300] [iter   20358] [loss 0.03259] [av. R 0.85906] [av. Q 1.81338]\n",
      "[epoch   55/300] [iter   20735] [loss 0.04466] [av. R 0.87181] [av. Q 1.82485]\n",
      "[epoch   56/300] [iter   21112] [loss 0.04017] [av. R 0.90115] [av. Q 1.83166]\n",
      "[epoch   57/300] [iter   21489] [loss 0.03161] [av. R 0.83777] [av. Q 1.81657]\n",
      "[epoch   58/300] [iter   21866] [loss 0.03639] [av. R 0.88940] [av. Q 1.86596]\n",
      "[epoch   59/300] [iter   22243] [loss 0.03380] [av. R 0.84608] [av. Q 1.78053]\n",
      "Copying Q weights\n",
      "[epoch   60/300] [iter   22620] [loss 0.05841] [av. R 0.87299] [av. Q 2.24212]\n",
      "[epoch   61/300] [iter   22997] [loss 0.05163] [av. R 0.91768] [av. Q 2.24542]\n",
      "[epoch   62/300] [iter   23374] [loss 0.04096] [av. R 0.86424] [av. Q 2.24584]\n",
      "[epoch   63/300] [iter   23751] [loss 0.04122] [av. R 0.84921] [av. Q 2.24663]\n",
      "[epoch   64/300] [iter   24128] [loss 0.03136] [av. R 0.87274] [av. Q 2.26526]\n",
      "[epoch   65/300] [iter   24505] [loss 0.03682] [av. R 0.84990] [av. Q 2.25270]\n",
      "[epoch   66/300] [iter   24882] [loss 0.03571] [av. R 0.89263] [av. Q 2.23142]\n",
      "[epoch   67/300] [iter   25259] [loss 0.03306] [av. R 0.88624] [av. Q 2.24096]\n",
      "[epoch   68/300] [iter   25636] [loss 0.04383] [av. R 0.85579] [av. Q 2.24145]\n",
      "[epoch   69/300] [iter   26013] [loss 0.02909] [av. R 0.88054] [av. Q 2.25321]\n",
      "[epoch   70/300] [iter   26390] [loss 0.03757] [av. R 0.87528] [av. Q 2.23743]\n",
      "[epoch   71/300] [iter   26767] [loss 0.03654] [av. R 0.87614] [av. Q 2.24221]\n",
      "[epoch   72/300] [iter   27144] [loss 0.02877] [av. R 0.87150] [av. Q 2.23632]\n",
      "[epoch   73/300] [iter   27521] [loss 0.03890] [av. R 0.86457] [av. Q 2.23127]\n",
      "[epoch   74/300] [iter   27898] [loss 0.03723] [av. R 0.88218] [av. Q 2.24925]\n",
      "[epoch   75/300] [iter   28275] [loss 0.03707] [av. R 0.86057] [av. Q 2.24958]\n",
      "[epoch   76/300] [iter   28652] [loss 0.03389] [av. R 0.86940] [av. Q 2.22962]\n",
      "[epoch   77/300] [iter   29029] [loss 0.04092] [av. R 0.87043] [av. Q 2.26701]\n",
      "[epoch   78/300] [iter   29406] [loss 0.03873] [av. R 0.85356] [av. Q 2.25364]\n",
      "[epoch   79/300] [iter   29783] [loss 0.03428] [av. R 0.84690] [av. Q 2.24065]\n",
      "Copying Q weights\n",
      "[epoch   80/300] [iter   30160] [loss 0.06681] [av. R 0.87176] [av. Q 2.55225]\n",
      "[epoch   81/300] [iter   30537] [loss 0.03202] [av. R 0.86663] [av. Q 2.54032]\n",
      "[epoch   82/300] [iter   30914] [loss 0.04244] [av. R 0.88180] [av. Q 2.55210]\n",
      "[epoch   83/300] [iter   31291] [loss 0.02885] [av. R 0.89197] [av. Q 2.53747]\n",
      "[epoch   84/300] [iter   31668] [loss 0.02667] [av. R 0.87823] [av. Q 2.52974]\n",
      "[epoch   85/300] [iter   32045] [loss 0.03216] [av. R 0.86371] [av. Q 2.54689]\n",
      "[epoch   86/300] [iter   32422] [loss 0.03568] [av. R 0.87847] [av. Q 2.54327]\n",
      "[epoch   87/300] [iter   32799] [loss 0.03293] [av. R 0.88774] [av. Q 2.52820]\n",
      "[epoch   88/300] [iter   33176] [loss 0.03513] [av. R 0.89087] [av. Q 2.54932]\n",
      "[epoch   89/300] [iter   33553] [loss 0.03455] [av. R 0.85623] [av. Q 2.51285]\n",
      "[epoch   90/300] [iter   33930] [loss 0.03504] [av. R 0.88173] [av. Q 2.52830]\n",
      "[epoch   91/300] [iter   34307] [loss 0.03503] [av. R 0.88301] [av. Q 2.54758]\n",
      "[epoch   92/300] [iter   34684] [loss 0.04363] [av. R 0.81518] [av. Q 2.54276]\n",
      "[epoch   93/300] [iter   35061] [loss 0.02881] [av. R 0.87633] [av. Q 2.52198]\n",
      "[epoch   94/300] [iter   35438] [loss 0.03061] [av. R 0.86721] [av. Q 2.53116]\n",
      "[epoch   95/300] [iter   35815] [loss 0.03736] [av. R 0.86424] [av. Q 2.53951]\n",
      "[epoch   96/300] [iter   36192] [loss 0.03246] [av. R 0.88999] [av. Q 2.53338]\n",
      "[epoch   97/300] [iter   36569] [loss 0.03498] [av. R 0.90152] [av. Q 2.55551]\n",
      "[epoch   98/300] [iter   36946] [loss 0.03253] [av. R 0.87132] [av. Q 2.52081]\n",
      "[epoch   99/300] [iter   37323] [loss 0.04205] [av. R 0.86195] [av. Q 2.52186]\n",
      "Copying Q weights\n",
      "[epoch  100/300] [iter   37700] [loss 0.03641] [av. R 0.86946] [av. Q 2.72426]\n",
      "[epoch  101/300] [iter   38077] [loss 0.03386] [av. R 0.85550] [av. Q 2.72431]\n",
      "[epoch  102/300] [iter   38454] [loss 0.04015] [av. R 0.88144] [av. Q 2.71720]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch  103/300] [iter   38831] [loss 0.03553] [av. R 0.84608] [av. Q 2.69608]\n",
      "[epoch  104/300] [iter   39208] [loss 0.03195] [av. R 0.86105] [av. Q 2.72548]\n",
      "[epoch  105/300] [iter   39585] [loss 0.02838] [av. R 0.86121] [av. Q 2.71175]\n",
      "[epoch  106/300] [iter   39962] [loss 0.04158] [av. R 0.85442] [av. Q 2.72222]\n",
      "[epoch  107/300] [iter   40339] [loss 0.03185] [av. R 0.86171] [av. Q 2.68935]\n",
      "[epoch  108/300] [iter   40716] [loss 0.03137] [av. R 0.87957] [av. Q 2.70890]\n",
      "[epoch  109/300] [iter   41093] [loss 0.02390] [av. R 0.88340] [av. Q 2.69548]\n",
      "[epoch  110/300] [iter   41470] [loss 0.03320] [av. R 0.86400] [av. Q 2.72300]\n",
      "[epoch  111/300] [iter   41847] [loss 0.02865] [av. R 0.86900] [av. Q 2.71391]\n",
      "[epoch  112/300] [iter   42224] [loss 0.02757] [av. R 0.86060] [av. Q 2.71361]\n",
      "[epoch  113/300] [iter   42601] [loss 0.03333] [av. R 0.89087] [av. Q 2.72442]\n",
      "[epoch  114/300] [iter   42978] [loss 0.03447] [av. R 0.87928] [av. Q 2.71272]\n",
      "[epoch  115/300] [iter   43355] [loss 0.02871] [av. R 0.86900] [av. Q 2.71391]\n",
      "[epoch  116/300] [iter   43732] [loss 0.02955] [av. R 0.87013] [av. Q 2.70875]\n",
      "[epoch  117/300] [iter   44109] [loss 0.02862] [av. R 0.89343] [av. Q 2.71963]\n",
      "[epoch  118/300] [iter   44486] [loss 0.03025] [av. R 0.86560] [av. Q 2.71654]\n",
      "[epoch  119/300] [iter   44863] [loss 0.03143] [av. R 0.87793] [av. Q 2.69235]\n",
      "Copying Q weights\n",
      "[epoch  120/300] [iter   45240] [loss 0.02233] [av. R 0.88512] [av. Q 2.81343]\n",
      "[epoch  121/300] [iter   45617] [loss 0.02930] [av. R 0.86547] [av. Q 2.81242]\n",
      "[epoch  122/300] [iter   45994] [loss 0.03892] [av. R 0.87789] [av. Q 2.84062]\n",
      "[epoch  123/300] [iter   46371] [loss 0.02841] [av. R 0.83777] [av. Q 2.82061]\n",
      "[epoch  124/300] [iter   46748] [loss 0.03135] [av. R 0.85994] [av. Q 2.81482]\n",
      "[epoch  125/300] [iter   47125] [loss 0.02994] [av. R 0.86906] [av. Q 2.79878]\n",
      "[epoch  126/300] [iter   47502] [loss 0.03060] [av. R 0.88930] [av. Q 2.82799]\n",
      "[epoch  127/300] [iter   47879] [loss 0.02970] [av. R 0.85380] [av. Q 2.81090]\n",
      "[epoch  128/300] [iter   48256] [loss 0.02820] [av. R 0.87274] [av. Q 2.83829]\n",
      "[epoch  129/300] [iter   48633] [loss 0.03676] [av. R 0.86839] [av. Q 2.81966]\n",
      "[epoch  130/300] [iter   49010] [loss 0.03185] [av. R 0.85339] [av. Q 2.82045]\n",
      "[epoch  131/300] [iter   49387] [loss 0.03679] [av. R 0.85470] [av. Q 2.82819]\n",
      "[epoch  132/300] [iter   49764] [loss 0.02338] [av. R 0.90100] [av. Q 2.81065]\n",
      "[epoch  133/300] [iter   50141] [loss 0.03582] [av. R 0.83935] [av. Q 2.85596]\n",
      "[epoch  134/300] [iter   50518] [loss 0.04015] [av. R 0.85157] [av. Q 2.82134]\n",
      "[epoch  135/300] [iter   50895] [loss 0.03262] [av. R 0.86856] [av. Q 2.82815]\n",
      "[epoch  136/300] [iter   51272] [loss 0.03191] [av. R 0.86203] [av. Q 2.80949]\n",
      "[epoch  137/300] [iter   51649] [loss 0.02967] [av. R 0.86220] [av. Q 2.80874]\n",
      "[epoch  138/300] [iter   52026] [loss 0.03173] [av. R 0.86807] [av. Q 2.81206]\n",
      "[epoch  139/300] [iter   52403] [loss 0.04026] [av. R 0.87038] [av. Q 2.79610]\n",
      "Copying Q weights\n",
      "[epoch  140/300] [iter   52780] [loss 0.03315] [av. R 0.87927] [av. Q 2.88850]\n",
      "[epoch  141/300] [iter   53157] [loss 0.03534] [av. R 0.85279] [av. Q 2.87385]\n",
      "[epoch  142/300] [iter   53534] [loss 0.04473] [av. R 0.86164] [av. Q 2.89064]\n",
      "[epoch  143/300] [iter   53911] [loss 0.03475] [av. R 0.84962] [av. Q 2.88772]\n",
      "[epoch  144/300] [iter   54288] [loss 0.02538] [av. R 0.87946] [av. Q 2.87109]\n",
      "[epoch  145/300] [iter   54665] [loss 0.03819] [av. R 0.86195] [av. Q 2.86945]\n",
      "[epoch  146/300] [iter   55042] [loss 0.03183] [av. R 0.87476] [av. Q 2.90321]\n",
      "[epoch  147/300] [iter   55419] [loss 0.03019] [av. R 0.85994] [av. Q 2.87889]\n",
      "[epoch  148/300] [iter   55796] [loss 0.03212] [av. R 0.85756] [av. Q 2.87408]\n",
      "[epoch  149/300] [iter   56173] [loss 0.03010] [av. R 0.86096] [av. Q 2.86749]\n",
      "[epoch  150/300] [iter   56550] [loss 0.02509] [av. R 0.89773] [av. Q 2.87800]\n",
      "[epoch  151/300] [iter   56927] [loss 0.03556] [av. R 0.84990] [av. Q 2.88930]\n",
      "[epoch  152/300] [iter   57304] [loss 0.03584] [av. R 0.85807] [av. Q 2.87723]\n",
      "[epoch  153/300] [iter   57681] [loss 0.02934] [av. R 0.85550] [av. Q 2.89136]\n",
      "[epoch  154/300] [iter   58058] [loss 0.02587] [av. R 0.89313] [av. Q 2.88769]\n",
      "[epoch  155/300] [iter   58435] [loss 0.02798] [av. R 0.89002] [av. Q 2.89234]\n",
      "[epoch  156/300] [iter   58812] [loss 0.03527] [av. R 0.85113] [av. Q 2.90737]\n",
      "[epoch  157/300] [iter   59189] [loss 0.02817] [av. R 0.85320] [av. Q 2.90505]\n",
      "[epoch  158/300] [iter   59566] [loss 0.03434] [av. R 0.85473] [av. Q 2.87724]\n",
      "[epoch  159/300] [iter   59943] [loss 0.02160] [av. R 0.88512] [av. Q 2.87383]\n",
      "Copying Q weights\n",
      "[epoch  160/300] [iter   60320] [loss 0.03533] [av. R 0.84990] [av. Q 2.93383]\n",
      "[epoch  161/300] [iter   60697] [loss 0.03842] [av. R 0.83327] [av. Q 2.95495]\n",
      "[epoch  162/300] [iter   61074] [loss 0.02763] [av. R 0.87738] [av. Q 2.91609]\n",
      "[epoch  163/300] [iter   61451] [loss 0.03635] [av. R 0.85532] [av. Q 2.94421]\n",
      "[epoch  164/300] [iter   61828] [loss 0.03143] [av. R 0.83777] [av. Q 2.91991]\n",
      "[epoch  165/300] [iter   62205] [loss 0.03376] [av. R 0.90115] [av. Q 2.93527]\n",
      "[epoch  166/300] [iter   62582] [loss 0.03556] [av. R 0.84549] [av. Q 2.93054]\n",
      "[epoch  167/300] [iter   62959] [loss 0.02991] [av. R 0.87957] [av. Q 2.92786]\n",
      "[epoch  168/300] [iter   63336] [loss 0.03197] [av. R 0.87314] [av. Q 2.92307]\n",
      "[epoch  169/300] [iter   63713] [loss 0.04037] [av. R 0.88105] [av. Q 2.92843]\n",
      "[epoch  170/300] [iter   64090] [loss 0.02092] [av. R 0.88957] [av. Q 2.89885]\n",
      "[epoch  171/300] [iter   64467] [loss 0.02994] [av. R 0.85339] [av. Q 2.92650]\n",
      "[epoch  172/300] [iter   64844] [loss 0.03959] [av. R 0.87038] [av. Q 2.90776]\n",
      "[epoch  173/300] [iter   65221] [loss 0.03182] [av. R 0.91768] [av. Q 2.92891]\n",
      "[epoch  174/300] [iter   65598] [loss 0.03770] [av. R 0.83327] [av. Q 2.95495]\n",
      "[epoch  175/300] [iter   65975] [loss 0.02987] [av. R 0.86014] [av. Q 2.91154]\n",
      "[epoch  176/300] [iter   66352] [loss 0.02569] [av. R 0.87588] [av. Q 2.92222]\n",
      "[epoch  177/300] [iter   66729] [loss 0.02480] [av. R 0.86851] [av. Q 2.93224]\n",
      "[epoch  178/300] [iter   67106] [loss 0.03081] [av. R 0.88173] [av. Q 2.92463]\n",
      "[epoch  179/300] [iter   67483] [loss 0.02719] [av. R 0.84608] [av. Q 2.93437]\n",
      "Copying Q weights\n",
      "[epoch  180/300] [iter   67860] [loss 0.03014] [av. R 0.84653] [av. Q 2.96001]\n",
      "[epoch  181/300] [iter   68237] [loss 0.03782] [av. R 0.81518] [av. Q 2.96353]\n",
      "[epoch  182/300] [iter   68614] [loss 0.02866] [av. R 0.86246] [av. Q 2.95517]\n",
      "[epoch  183/300] [iter   68991] [loss 0.02867] [av. R 0.89456] [av. Q 2.94169]\n",
      "[epoch  184/300] [iter   69368] [loss 0.02820] [av. R 0.86420] [av. Q 2.97292]\n",
      "[epoch  185/300] [iter   69745] [loss 0.03476] [av. R 0.87003] [av. Q 2.93722]\n",
      "[epoch  186/300] [iter   70122] [loss 0.03430] [av. R 0.86815] [av. Q 2.94957]\n",
      "[epoch  187/300] [iter   70499] [loss 0.03591] [av. R 0.86457] [av. Q 2.95613]\n",
      "[epoch  188/300] [iter   70876] [loss 0.02465] [av. R 0.86411] [av. Q 2.96741]\n",
      "[epoch  189/300] [iter   71253] [loss 0.03267] [av. R 0.88101] [av. Q 2.96891]\n",
      "[epoch  190/300] [iter   71630] [loss 0.03713] [av. R 0.87176] [av. Q 2.95122]\n",
      "[epoch  191/300] [iter   72007] [loss 0.02794] [av. R 0.86663] [av. Q 2.95768]\n",
      "[epoch  192/300] [iter   72384] [loss 0.03955] [av. R 0.85487] [av. Q 2.96381]\n",
      "[epoch  193/300] [iter   72761] [loss 0.03132] [av. R 0.87781] [av. Q 2.96601]\n",
      "[epoch  194/300] [iter   73138] [loss 0.02967] [av. R 0.85141] [av. Q 2.95825]\n",
      "[epoch  195/300] [iter   73515] [loss 0.03461] [av. R 0.85279] [av. Q 2.95468]\n",
      "[epoch  196/300] [iter   73892] [loss 0.02669] [av. R 0.87795] [av. Q 2.95258]\n",
      "[epoch  197/300] [iter   74269] [loss 0.04445] [av. R 0.85758] [av. Q 2.96369]\n",
      "[epoch  198/300] [iter   74646] [loss 0.02690] [av. R 0.87205] [av. Q 2.95107]\n",
      "[epoch  199/300] [iter   75023] [loss 0.03331] [av. R 0.86498] [av. Q 2.97112]\n",
      "Copying Q weights\n",
      "[epoch  200/300] [iter   75400] [loss 0.03553] [av. R 0.87143] [av. Q 2.96333]\n",
      "[epoch  201/300] [iter   75777] [loss 0.03452] [av. R 0.86547] [av. Q 2.97385]\n",
      "[epoch  202/300] [iter   76154] [loss 0.02722] [av. R 0.89002] [av. Q 2.96958]\n",
      "[epoch  203/300] [iter   76531] [loss 0.03262] [av. R 0.89508] [av. Q 2.97745]\n",
      "[epoch  204/300] [iter   76908] [loss 0.03477] [av. R 0.85579] [av. Q 2.96848]\n",
      "[epoch  205/300] [iter   77285] [loss 0.02790] [av. R 0.86420] [av. Q 2.97873]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch  206/300] [iter   77662] [loss 0.03869] [av. R 0.84132] [av. Q 2.98370]\n",
      "[epoch  207/300] [iter   78039] [loss 0.02623] [av. R 0.87155] [av. Q 2.97897]\n",
      "[epoch  208/300] [iter   78416] [loss 0.03092] [av. R 0.87022] [av. Q 2.95872]\n",
      "[epoch  209/300] [iter   78793] [loss 0.02815] [av. R 0.86105] [av. Q 2.97011]\n",
      "[epoch  210/300] [iter   79170] [loss 0.03173] [av. R 0.88580] [av. Q 2.97465]\n",
      "[epoch  211/300] [iter   79547] [loss 0.02796] [av. R 0.88372] [av. Q 2.96911]\n",
      "[epoch  212/300] [iter   79924] [loss 0.02815] [av. R 0.86105] [av. Q 2.97011]\n",
      "[epoch  213/300] [iter   80301] [loss 0.03428] [av. R 0.86815] [av. Q 2.96002]\n",
      "[epoch  214/300] [iter   80678] [loss 0.02677] [av. R 0.86024] [av. Q 2.97321]\n",
      "[epoch  215/300] [iter   81055] [loss 0.03150] [av. R 0.84076] [av. Q 2.95854]\n",
      "[epoch  216/300] [iter   81432] [loss 0.02182] [av. R 0.88553] [av. Q 2.97814]\n",
      "[epoch  217/300] [iter   81809] [loss 0.03031] [av. R 0.87022] [av. Q 2.95872]\n",
      "[epoch  218/300] [iter   82186] [loss 0.03247] [av. R 0.84940] [av. Q 2.96474]\n",
      "[epoch  219/300] [iter   82563] [loss 0.02783] [av. R 0.87274] [av. Q 2.97947]\n",
      "Copying Q weights\n",
      "[epoch  220/300] [iter   82940] [loss 0.02873] [av. R 0.87481] [av. Q 2.96125]\n",
      "[epoch  221/300] [iter   83317] [loss 0.03146] [av. R 0.90273] [av. Q 2.97809]\n",
      "[epoch  222/300] [iter   83694] [loss 0.02125] [av. R 0.87823] [av. Q 2.96506]\n",
      "[epoch  223/300] [iter   84071] [loss 0.02822] [av. R 0.88159] [av. Q 2.97073]\n",
      "[epoch  224/300] [iter   84448] [loss 0.03559] [av. R 0.84700] [av. Q 2.97419]\n",
      "[epoch  225/300] [iter   84825] [loss 0.02258] [av. R 0.88693] [av. Q 2.97311]\n",
      "[epoch  226/300] [iter   85202] [loss 0.02599] [av. R 0.87220] [av. Q 2.97075]\n",
      "[epoch  227/300] [iter   85579] [loss 0.02885] [av. R 0.86371] [av. Q 2.98078]\n",
      "[epoch  228/300] [iter   85956] [loss 0.03029] [av. R 0.86940] [av. Q 2.97737]\n",
      "[epoch  229/300] [iter   86333] [loss 0.03339] [av. R 0.85807] [av. Q 2.99186]\n",
      "[epoch  230/300] [iter   86710] [loss 0.02434] [av. R 0.87722] [av. Q 2.96962]\n",
      "[epoch  231/300] [iter   87087] [loss 0.03142] [av. R 0.86946] [av. Q 2.97207]\n",
      "[epoch  232/300] [iter   87464] [loss 0.03268] [av. R 0.86048] [av. Q 2.98674]\n",
      "[epoch  233/300] [iter   87841] [loss 0.02714] [av. R 0.89002] [av. Q 2.97438]\n",
      "[epoch  234/300] [iter   88218] [loss 0.03182] [av. R 0.84589] [av. Q 2.97630]\n",
      "[epoch  235/300] [iter   88595] [loss 0.03012] [av. R 0.86481] [av. Q 2.97048]\n",
      "[epoch  236/300] [iter   88972] [loss 0.03313] [av. R 0.87052] [av. Q 2.96868]\n",
      "[epoch  237/300] [iter   89349] [loss 0.02481] [av. R 0.87696] [av. Q 2.98080]\n",
      "[epoch  238/300] [iter   89726] [loss 0.03094] [av. R 0.90115] [av. Q 2.97912]\n",
      "[epoch  239/300] [iter   90103] [loss 0.02735] [av. R 0.87582] [av. Q 2.96583]\n",
      "Copying Q weights\n",
      "[epoch  240/300] [iter   90480] [loss 0.02399] [av. R 0.89773] [av. Q 2.98453]\n",
      "[epoch  241/300] [iter   90857] [loss 0.03067] [av. R 0.86114] [av. Q 2.99549]\n",
      "[epoch  242/300] [iter   91234] [loss 0.02900] [av. R 0.91237] [av. Q 2.96254]\n",
      "[epoch  243/300] [iter   91611] [loss 0.03152] [av. R 0.84076] [av. Q 2.96922]\n",
      "[epoch  244/300] [iter   91988] [loss 0.02692] [av. R 0.86906] [av. Q 2.98819]\n",
      "[epoch  245/300] [iter   92365] [loss 0.02503] [av. R 0.88522] [av. Q 2.98244]\n",
      "[epoch  246/300] [iter   92742] [loss 0.02637] [av. R 0.86475] [av. Q 2.95979]\n",
      "[epoch  247/300] [iter   93119] [loss 0.02963] [av. R 0.86591] [av. Q 2.96634]\n",
      "[epoch  248/300] [iter   93496] [loss 0.02899] [av. R 0.91237] [av. Q 2.96254]\n",
      "[epoch  249/300] [iter   93873] [loss 0.02819] [av. R 0.89263] [av. Q 2.97197]\n",
      "[epoch  250/300] [iter   94250] [loss 0.03263] [av. R 0.89029] [av. Q 2.98862]\n",
      "[epoch  251/300] [iter   94627] [loss 0.03914] [av. R 0.88105] [av. Q 2.96970]\n",
      "[epoch  252/300] [iter   95004] [loss 0.03104] [av. R 0.86428] [av. Q 2.96712]\n",
      "[epoch  253/300] [iter   95381] [loss 0.02503] [av. R 0.87805] [av. Q 2.98193]\n",
      "[epoch  254/300] [iter   95758] [loss 0.03458] [av. R 0.88840] [av. Q 2.97061]\n",
      "[epoch  255/300] [iter   96135] [loss 0.02708] [av. R 0.85380] [av. Q 2.98678]\n",
      "[epoch  256/300] [iter   96512] [loss 0.02902] [av. R 0.85141] [av. Q 2.97981]\n",
      "[epoch  257/300] [iter   96889] [loss 0.02989] [av. R 0.87344] [av. Q 2.97624]\n",
      "[epoch  258/300] [iter   97266] [loss 0.02711] [av. R 0.85396] [av. Q 2.97378]\n",
      "[epoch  259/300] [iter   97643] [loss 0.03379] [av. R 0.84056] [av. Q 2.98466]\n",
      "Copying Q weights\n",
      "[epoch  260/300] [iter   98020] [loss 0.03106] [av. R 0.87848] [av. Q 2.98193]\n",
      "[epoch  261/300] [iter   98397] [loss 0.02946] [av. R 0.85153] [av. Q 2.97625]\n",
      "[epoch  262/300] [iter   98774] [loss 0.02560] [av. R 0.87155] [av. Q 2.99350]\n",
      "[epoch  263/300] [iter   99151] [loss 0.02410] [av. R 0.86411] [av. Q 2.98786]\n",
      "[epoch  264/300] [iter   99528] [loss 0.02526] [av. R 0.88196] [av. Q 2.97512]\n",
      "[epoch  265/300] [iter   99905] [loss 0.03115] [av. R 0.84777] [av. Q 2.97716]\n",
      "[epoch  266/300] [iter  100282] [loss 0.03091] [av. R 0.88147] [av. Q 2.97386]\n",
      "[epoch  267/300] [iter  100659] [loss 0.03790] [av. R 0.89436] [av. Q 2.97534]\n",
      "[epoch  268/300] [iter  101036] [loss 0.03456] [av. R 0.86342] [av. Q 2.97755]\n",
      "[epoch  269/300] [iter  101413] [loss 0.03127] [av. R 0.84368] [av. Q 2.98962]\n",
      "[epoch  270/300] [iter  101790] [loss 0.02751] [av. R 0.88524] [av. Q 2.97644]\n",
      "[epoch  271/300] [iter  102167] [loss 0.02676] [av. R 0.86906] [av. Q 2.99062]\n",
      "[epoch  272/300] [iter  102544] [loss 0.03887] [av. R 0.84132] [av. Q 2.98669]\n",
      "[epoch  273/300] [iter  102921] [loss 0.03644] [av. R 0.85487] [av. Q 2.98501]\n",
      "[epoch  274/300] [iter  103298] [loss 0.02490] [av. R 0.86959] [av. Q 2.98442]\n",
      "[epoch  275/300] [iter  103675] [loss 0.02839] [av. R 0.87847] [av. Q 2.98075]\n",
      "[epoch  276/300] [iter  104052] [loss 0.02484] [av. R 0.89313] [av. Q 2.97874]\n",
      "[epoch  277/300] [iter  104429] [loss 0.02627] [av. R 0.88999] [av. Q 2.97543]\n",
      "[epoch  278/300] [iter  104806] [loss 0.02532] [av. R 0.88538] [av. Q 2.98092]\n",
      "[epoch  279/300] [iter  105183] [loss 0.03089] [av. R 0.89326] [av. Q 2.97811]\n",
      "Copying Q weights\n",
      "[epoch  280/300] [iter  105560] [loss 0.03107] [av. R 0.85473] [av. Q 2.96609]\n",
      "[epoch  281/300] [iter  105937] [loss 0.03049] [av. R 0.86210] [av. Q 2.97923]\n",
      "[epoch  282/300] [iter  106314] [loss 0.02430] [av. R 0.86411] [av. Q 2.97461]\n",
      "[epoch  283/300] [iter  106691] [loss 0.03173] [av. R 0.86057] [av. Q 2.96780]\n",
      "[epoch  284/300] [iter  107068] [loss 0.03030] [av. R 0.86210] [av. Q 2.97923]\n",
      "[epoch  285/300] [iter  107445] [loss 0.03389] [av. R 0.84056] [av. Q 2.96930]\n",
      "[epoch  286/300] [iter  107822] [loss 0.02997] [av. R 0.87324] [av. Q 2.97227]\n",
      "[epoch  287/300] [iter  108199] [loss 0.02967] [av. R 0.86940] [av. Q 2.97555]\n",
      "[epoch  288/300] [iter  108576] [loss 0.04342] [av. R 0.86164] [av. Q 2.96547]\n",
      "[epoch  289/300] [iter  108953] [loss 0.03129] [av. R 0.89083] [av. Q 2.98154]\n",
      "[epoch  290/300] [iter  109330] [loss 0.02901] [av. R 0.91237] [av. Q 2.95249]\n",
      "[epoch  291/300] [iter  109707] [loss 0.02857] [av. R 0.84834] [av. Q 2.95608]\n",
      "[epoch  292/300] [iter  110084] [loss 0.03148] [av. R 0.89667] [av. Q 2.96500]\n",
      "[epoch  293/300] [iter  110461] [loss 0.03182] [av. R 0.85113] [av. Q 2.97825]\n",
      "[epoch  294/300] [iter  110838] [loss 0.02855] [av. R 0.84834] [av. Q 2.95608]\n",
      "[epoch  295/300] [iter  111215] [loss 0.02663] [av. R 0.88372] [av. Q 2.95913]\n",
      "[epoch  296/300] [iter  111592] [loss 0.02621] [av. R 0.89088] [av. Q 2.96617]\n",
      "[epoch  297/300] [iter  111969] [loss 0.03282] [av. R 0.85807] [av. Q 2.98161]\n",
      "[epoch  298/300] [iter  112346] [loss 0.03064] [av. R 0.87848] [av. Q 2.97022]\n",
      "[epoch  299/300] [iter  112723] [loss 0.02832] [av. R 0.88352] [av. Q 2.95729]\n",
      "Copying Q weights\n",
      "[epoch  300/300] [iter  113100] [loss 0.03083] [av. R 0.89326] [av. Q 2.96065]\n",
      "Saved model!\n",
      "\tmodels\\dqn.all3Replays.pt\n"
     ]
    }
   ],
   "source": [
    "def runTraining(coefOverrides):    \n",
    "    combinedStates  = pd.concat([game['expertStates']  for game in GAMES])\n",
    "    combinedActions = pd.concat([game['expertActions'] for game in GAMES])\n",
    "    \n",
    "    dataBatches, stateSz, actionSz = libPreprocess.dataToBatches(\n",
    "        combinedStates, combinedActions, BATCH_SZ, \n",
    "        includeRewards=True, coefOverrides=coefOverrides\n",
    "    )\n",
    "    qModel1 = SAtoV_Model(stateSz, actionSz, DEVICE)\n",
    "    qModel2 = SAtoV_Model(stateSz, actionSz, DEVICE)\n",
    "    qModel2.load_state_dict(qModel1.state_dict())\n",
    "    qModel2.eval()\n",
    "    \n",
    "    train_behavioral_cloning(dataBatches, qModel1, qModel2)\n",
    "    return qModel1\n",
    "\n",
    "model = runTraining({})\n",
    "model.save(\"dqn.all3Replays\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment this code to run the forwards-penalized validation\n",
    "\n",
    "# Penalize driving forwards, and not turning:\n",
    "#forwardsPenaltyCoef = {}\n",
    "#for key in libRewards.DEFAULT_COEF.keys():\n",
    "#    forwardsPenaltyCoef[key] = 0.0\n",
    "#forwardsPenaltyCoef['forwards']  = -2.0\n",
    "#forwardsPenaltyCoef['action']    = 1.0\n",
    "#forwardsPenaltyCoef['const']     = 2.0 # keep positive\n",
    "\n",
    "#model = runTraining(forwardsPenaltyCoef)\n",
    "#model.save(\"dqn.forwardPenalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
